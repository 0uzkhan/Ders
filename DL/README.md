# <center>BIL365 - Derin Ã–ÄŸrenme</center>

- *DeÄŸerlendirme Sistemi*:
    - Ara SÄ±nav: 40%
        - SÄ±nav: 100%
    - Final: 60%
        - Proje: 100%
<hr>

# Ders NotlarÄ±

## Ä°Ã§indekiler
- [BIL365 - Derin Ã–ÄŸrenme](#bil365---derin-Ã¶ÄŸrenme)
- [Ders NotlarÄ±](#ders-notlarÄ±)
  - [Ä°Ã§indekiler](#iÌ‡Ã§indekiler)
  - [ğŸ§­ SÄ±nav KonularÄ± Ä°ndeksi](#-sÄ±nav-konularÄ±-iÌ‡ndeksi)
    - [ğŸ§  1. Temel TanÄ±mlar (AI, ML, DL, YSA)](#-1-temel-tanÄ±mlar-ai-ml-dl-ysa)
    - [âš–ï¸ 2. Makine Ã–ÄŸrenmesi vs. Derin Ã–ÄŸrenme](#ï¸-2-makine-Ã¶ÄŸrenmesi-vs-derin-Ã¶ÄŸrenme)
    - [ğŸ§ 3. AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting)](#-3-aÅŸÄ±rÄ±-Ã¶ÄŸrenme-overfitting)
    - [ğŸ–¼ï¸ 4. CNN ve Max Pooling Ne Yapar?](#ï¸-4-cnn-ve-max-pooling-ne-yapar)
    - [ğŸ§± 5. Katman TÃ¼rleri ve DiÄŸer Temel TanÄ±mlar](#-5-katman-tÃ¼rleri-ve-diÄŸer-temel-tanÄ±mlar)
  - [GiriÅŸ: Yapay Zeka, Makine Ã–ÄŸrenmesi, Derin Ã–ÄŸrenme](#giriÅŸ-yapay-zeka-makine-Ã¶ÄŸrenmesi-derin-Ã¶ÄŸrenme)
    - [Ã–zet](#Ã¶zet)
    - [Temel Kavramlar](#temel-kavramlar)
    - [Ä°puÃ§larÄ± / Notlar](#iÌ‡puÃ§larÄ±--notlar)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular)
  - [Makine Ã–ÄŸrenmesi vs Derin Ã–ÄŸrenme: KarÅŸÄ±laÅŸtÄ±rma](#makine-Ã¶ÄŸrenmesi-vs-derin-Ã¶ÄŸrenme-karÅŸÄ±laÅŸtÄ±rma)
    - [Ã–zet](#Ã¶zet-1)
    - [Ä°puÃ§larÄ± / Notlar](#iÌ‡puÃ§larÄ±--notlar-1)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-1)
  - [ML vs DL: Kavramlar](#ml-vs-dl-kavramlar)
  - [ML vs DL: Ã–zellik Ã‡Ä±karÄ±mÄ±](#ml-vs-dl-Ã¶zellik-Ã§Ä±karÄ±mÄ±)
  - [ML vs DL: Veri Ä°htiyacÄ±](#ml-vs-dl-veri-iÌ‡htiyacÄ±)
  - [ML vs DL: Model KarmaÅŸÄ±klÄ±ÄŸÄ±](#ml-vs-dl-model-karmaÅŸÄ±klÄ±ÄŸÄ±)
  - [ML vs DL: DonanÄ±m ve Hesaplama](#ml-vs-dl-donanÄ±m-ve-hesaplama)
  - [ML vs DL: Uygulama Ã–rnekleri](#ml-vs-dl-uygulama-Ã¶rnekleri)
  - [Yapay ZekanÄ±n TarihÃ§esi (1943â€“2009)](#yapay-zekanÄ±n-tarihÃ§esi-19432009)
    - [Ã–zet](#Ã¶zet-2)
    - [Zaman Ã‡izelgesi (SeÃ§me BaÅŸlÄ±klar)](#zaman-Ã§izelgesi-seÃ§me-baÅŸlÄ±klar)
    - [KavÅŸak NoktalarÄ± (Detay)](#kavÅŸak-noktalarÄ±-detay)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-2)
  - [1990'lar: MLP, Backprop, BPTT, CNN, LSTM](#1990lar-mlp-backprop-bptt-cnn-lstm)
    - [Ã–zet](#Ã¶zet-3)
    - [Temel Noktalar](#temel-noktalar)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-3)
  - [Erken DÃ¶nem: Neden BaÅŸarÄ±sÄ±z Oldu?](#erken-dÃ¶nem-neden-baÅŸarÄ±sÄ±z-oldu)
    - [Ã–zet](#Ã¶zet-4)
    - [Ana GerekÃ§eler](#ana-gerekÃ§eler)
    - [Notlar](#notlar)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-4)
  - [Derin Ã–ÄŸrenme: LeNet (1998) ve CNN'ler](#derin-Ã¶ÄŸrenme-lenet-1998-ve-cnnler)
    - [Ã–zet](#Ã¶zet-5)
    - [LeNet'in Temelleri](#lenetin-temelleri)
    - [Neden SÄ±nÄ±rlÄ± KaldÄ± (O DÃ¶nem)?](#neden-sÄ±nÄ±rlÄ±-kaldÄ±-o-dÃ¶nem)
    - [Notlar](#notlar-1)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-5)
  - [ImageNet ve ILSVRC (2009â€“2012)](#imagenet-ve-ilsvrc-20092012)
    - [Ã–zet](#Ã¶zet-6)
    - [Temel Noktalar](#temel-noktalar-1)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-6)
  - [AlexNet (2012): BaÅŸarÄ± ve Yenilikler](#alexnet-2012-baÅŸarÄ±-ve-yenilikler)
    - [Ã–zet](#Ã¶zet-7)
    - [Mimari ve Ã–lÃ§ek](#mimari-ve-Ã¶lÃ§ek)
    - [Ã–ne Ã‡Ä±kan Teknikler](#Ã¶ne-Ã§Ä±kan-teknikler)
    - [Notlar](#notlar-2)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-7)
    - [AlexNet: Torchvision ile Ã‡Ä±karÄ±m (GÃ¼ncel API)](#alexnet-torchvision-ile-Ã§Ä±karÄ±m-gÃ¼ncel-api)
  - [State-of-the-Art (SOTA) Modeller](#state-of-the-art-sota-modeller)
    - [Ã–zet](#Ã¶zet-8)
    - [RolÃ¼ ve BaÄŸlam](#rolÃ¼-ve-baÄŸlam)
    - [TemsilÃ® Aileler (BilgisayarlÄ± GÃ¶rÃ¼)](#temsilÃ®-aileler-bilgisayarlÄ±-gÃ¶rÃ¼)
    - [Kaynaklar](#kaynaklar)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-8)
  - [Transfer Ã–ÄŸrenme: Genel BakÄ±ÅŸ](#transfer-Ã¶ÄŸrenme-genel-bakÄ±ÅŸ)
    - [Ã–zet](#Ã¶zet-9)
    - [Neden Ä°ÅŸe Yarar?](#neden-iÌ‡ÅŸe-yarar)
  - [Transfer: Ã–zellik Ã‡Ä±karma (Feature Extraction)](#transfer-Ã¶zellik-Ã§Ä±karma-feature-extraction)
  - [Transfer: Ä°nce Ayar (Fine-Tuning)](#transfer-iÌ‡nce-ayar-fine-tuning)
  - [AlexNet â†’ CIFAR-10: Veri ve DÃ¶nÃ¼ÅŸÃ¼mler](#alexnet--cifar-10-veri-ve-dÃ¶nÃ¼ÅŸÃ¼mler)
  - [AlexNet â†’ CIFAR-10: Model ve Dondurma/Ã‡Ã¶zme](#alexnet--cifar-10-model-ve-dondurmaÃ§Ã¶zme)
  - [AlexNet Transfer: EÄŸitim ve DeÄŸerlendirme](#alexnet-transfer-eÄŸitim-ve-deÄŸerlendirme)
  - [VGG-16: Mimari ve Transfer](#vgg-16-mimari-ve-transfer)
    - [Ã–zet](#Ã¶zet-10)
    - [HÄ±zlÄ± Notlar](#hÄ±zlÄ±-notlar)
    - [Kod: Son KatmanÄ± DeÄŸiÅŸtir (CIFARâ€‘10)](#kod-son-katmanÄ±-deÄŸiÅŸtir-cifar10)
    - [Kod: Ã–zel SÄ±nÄ±flandÄ±rÄ±cÄ± BloÄŸu](#kod-Ã¶zel-sÄ±nÄ±flandÄ±rÄ±cÄ±-bloÄŸu)
  - [Derin AÄŸlarda Gradyan SorunlarÄ±](#derin-aÄŸlarda-gradyan-sorunlarÄ±)
    - [Vanishing Gradient (Kaybolan Gradyan)](#vanishing-gradient-kaybolan-gradyan)
    - [Exploding Gradient (Patlayan Gradyan)](#exploding-gradient-patlayan-gradyan)
    - [Ã‡Ã¶zÃ¼m YÃ¶ntemleri](#Ã§Ã¶zÃ¼m-yÃ¶ntemleri)
  - [ResNet: Residual BaÄŸlantÄ±lar](#resnet-residual-baÄŸlantÄ±lar)
    - [Ã–zet](#Ã¶zet-11)
    - [Kod: ResNet-50 Transfer (CIFARâ€‘10)](#kod-resnet-50-transfer-cifar10)
  - [Inception (GoogLeNet): Inception ModÃ¼lÃ¼](#inception-googlenet-inception-modÃ¼lÃ¼)
    - [Ã–zet](#Ã¶zet-12)
    - [Kod: Inception v3 Transfer (CIFARâ€‘10)](#kod-inception-v3-transfer-cifar10)
  - [MobileNet: Hafif Mimariler](#mobilenet-hafif-mimariler)
    - [Ã–zet](#Ã¶zet-13)
    - [Kod: MobileNetV2 Transfer (CIFARâ€‘10)](#kod-mobilenetv2-transfer-cifar10)
  - [EfficientNet: BileÅŸik Ã–lÃ§eklendirme](#efficientnet-bileÅŸik-Ã¶lÃ§eklendirme)
    - [Ã–zet](#Ã¶zet-14)
    - [Kod: EfficientNetâ€‘B0 Transfer (CIFARâ€‘10)](#kod-efficientnetb0-transfer-cifar10)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-9)
  - [AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting): TanÄ±m ve Belirtiler](#aÅŸÄ±rÄ±-Ã¶ÄŸrenme-overfitting-tanÄ±m-ve-belirtiler)
    - [TanÄ±m](#tanÄ±m)
    - [NasÄ±l AnlarÄ±z?](#nasÄ±l-anlarÄ±z)
  - [Train/Validation/Test: Neden ve NasÄ±l?](#trainvalidationtest-neden-ve-nasÄ±l)
  - [Validation Seti: Rol ve Hiperparametre AyarÄ±](#validation-seti-rol-ve-hiperparametre-ayarÄ±)
  - [Validation Seti: CIFAR-10 Ã–rnek (random\_split)](#validation-seti-cifar-10-Ã¶rnek-random_split)
  - [AÅŸÄ±rÄ± Ã–ÄŸrenmenin Nedenleri](#aÅŸÄ±rÄ±-Ã¶ÄŸrenmenin-nedenleri)
  - [AÅŸÄ±rÄ± Ã–ÄŸrenmeyi Ã–nleme: Veri OdaklÄ±](#aÅŸÄ±rÄ±-Ã¶ÄŸrenmeyi-Ã¶nleme-veri-odaklÄ±)
  - [AÅŸÄ±rÄ± Ã–ÄŸrenmeyi Ã–nleme: Model OdaklÄ±](#aÅŸÄ±rÄ±-Ã¶ÄŸrenmeyi-Ã¶nleme-model-odaklÄ±)
  - [DÃ¼zenlileÅŸtirme: Dropout, L1/L2 (Weight Decay)](#dÃ¼zenlileÅŸtirme-dropout-l1l2-weight-decay)
    - [Dropout](#dropout)
    - [L2 (Weight Decay)](#l2-weight-decay)
    - [L1 (Elle ekleme)](#l1-elle-ekleme)
  - [Erken Durdurma ve Batch Normalization](#erken-durdurma-ve-batch-normalization)
    - [Erken Durdurma (patience=5 Ã¶rneÄŸi)](#erken-durdurma-patience5-Ã¶rneÄŸi)
    - [Batch Normalization](#batch-normalization)
  - [Uygulama: Transfer Ã–ÄŸrenme KÄ±yaslama GÃ¶revi](#uygulama-transfer-Ã¶ÄŸrenme-kÄ±yaslama-gÃ¶revi)
  - [HiyerarÅŸik Temsil Ã–ÄŸrenimi](#hiyerarÅŸik-temsil-Ã¶ÄŸrenimi)
    - [Ã–zet](#Ã¶zet-15)
    - [Katmanlara GÃ¶re Ã–rnekler](#katmanlara-gÃ¶re-Ã¶rnekler)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-10)
  - [Derin Ã–ÄŸrenmede Zorluklar: Non-konveksite ve RastsallÄ±k](#derin-Ã¶ÄŸrenmede-zorluklar-non-konveksite-ve-rastsallÄ±k)
    - [Ã–zet](#Ã¶zet-16)
    - [Temel Noktalar](#temel-noktalar-2)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-11)
  - [Boru HatlarÄ± vs UÃ§tan Uca Sistemler](#boru-hatlarÄ±-vs-uÃ§tan-uca-sistemler)
    - [Ã–zet](#Ã¶zet-17)
    - [Notlar](#notlar-3)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-12)
  - [Yapay Sinir AÄŸlarÄ±: TanÄ±m ve BileÅŸenler](#yapay-sinir-aÄŸlarÄ±-tanÄ±m-ve-bileÅŸenler)
    - [Ã–zet](#Ã¶zet-18)
    - [Temel Kavramlar](#temel-kavramlar-1)
    - [Notlar](#notlar-4)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-13)
  - [NÃ¶ron Aktivasyonu ve Hesaplama](#nÃ¶ron-aktivasyonu-ve-hesaplama)
    - [Ã–zet](#Ã¶zet-19)
    - [Detaylar](#detaylar)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-14)
  - [Aktivasyon FonksiyonlarÄ±: Lineer, Sigmoid, Tanh, ReLU](#aktivasyon-fonksiyonlarÄ±-lineer-sigmoid-tanh-relu)
    - [Ã–zet](#Ã¶zet-20)
    - [TanÄ±mlar ve Ã–zellikler](#tanÄ±mlar-ve-Ã¶zellikler)
    - [Ä°puÃ§larÄ±](#iÌ‡puÃ§larÄ±)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-15)
  - [ReLU ve Seyrek Aktivite](#relu-ve-seyrek-aktivite)
    - [Ã–zet](#Ã¶zet-21)
    - [Mekanizma](#mekanizma)
    - [Neden Ã–nemli?](#neden-Ã¶nemli)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-16)
  - [Perceptron: Ä°leri YayÄ±lÄ±m](#perceptron-iÌ‡leri-yayÄ±lÄ±m)
    - [Ã–zet](#Ã¶zet-22)
    - [FormÃ¼l (Tek Ã‡Ä±kÄ±ÅŸ)](#formÃ¼l-tek-Ã§Ä±kÄ±ÅŸ)
    - [FormÃ¼l (Ã‡oklu Ã‡Ä±kÄ±ÅŸ / C sÄ±nÄ±f)](#formÃ¼l-Ã§oklu-Ã§Ä±kÄ±ÅŸ--c-sÄ±nÄ±f)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-17)
  - [Softmax Aktivasyonu ve Ã–zellikleri](#softmax-aktivasyonu-ve-Ã¶zellikleri)
    - [Ã–zet](#Ã¶zet-23)
    - [TanÄ±m](#tanÄ±m-1)
    - [Ã–zellikler](#Ã¶zellikler)
    - [Ä°puÃ§larÄ±](#iÌ‡puÃ§larÄ±-1)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-18)
  - [Tek Gizli KatmanlÄ± Sinir AÄŸÄ±](#tek-gizli-katmanlÄ±-sinir-aÄŸÄ±)
    - [Ã–zet](#Ã¶zet-24)
    - [FormÃ¼l ve Boyutlar](#formÃ¼l-ve-boyutlar)
    - [Notlar](#notlar-5)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-19)
  - [Ã‡ok KatmanlÄ± Perceptron (Genel Ä°leri YayÄ±lÄ±m)](#Ã§ok-katmanlÄ±-perceptron-genel-iÌ‡leri-yayÄ±lÄ±m)
    - [Ã–zet](#Ã¶zet-25)
    - [Ä°leri YayÄ±lÄ±m Denklemleri](#iÌ‡leri-yayÄ±lÄ±m-denklemleri)
    - [Toplam Parametre ve Hesaplama](#toplam-parametre-ve-hesaplama)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-20)
  - [Derin Sinir AÄŸÄ±](#derin-sinir-aÄŸÄ±)
    - [Ã–zet](#Ã¶zet-26)
    - [Notlar](#notlar-6)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-21)
  - [Ã–rnek: UÃ§uÅŸum Gecikecek mi?](#Ã¶rnek-uÃ§uÅŸum-gecikecek-mi)
    - [Problem TanÄ±mÄ±](#problem-tanÄ±mÄ±)
    - [Basit MLP Kurulumu (Ä°kili SÄ±nÄ±flandÄ±rma)](#basit-mlp-kurulumu-iÌ‡kili-sÄ±nÄ±flandÄ±rma)
    - [Notlar](#notlar-7)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-22)
  - [KayÄ±p FonksiyonlarÄ± ve Toplam KayÄ±p](#kayÄ±p-fonksiyonlarÄ±-ve-toplam-kayÄ±p)
    - [Ã‡apraz Entropi (Softmax â€“ Ã‡ok SÄ±nÄ±flÄ±)](#Ã§apraz-entropi-softmax--Ã§ok-sÄ±nÄ±flÄ±)
    - [Ä°kili Ã‡apraz Entropi (Sigmoid â€“ Ä°kili)](#iÌ‡kili-Ã§apraz-entropi-sigmoid--iÌ‡kili)
    - [Ortalama Kare Hata (Regresyon)](#ortalama-kare-hata-regresyon)
    - [Veri Ãœzerinde Toplam KayÄ±p ve DÃ¼zenlileÅŸtirme](#veri-Ã¼zerinde-toplam-kayÄ±p-ve-dÃ¼zenlileÅŸtirme)
    - [Notlar](#notlar-8)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-23)
  - [EÄŸitim SÃ¼reci ve Optimizasyon](#eÄŸitim-sÃ¼reci-ve-optimizasyon)
    - [Ã–zet](#Ã¶zet-27)
    - [AdÄ±m AdÄ±m (Epoch iÃ§inde)](#adÄ±m-adÄ±m-epoch-iÃ§inde)
    - [Terimler](#terimler)
    - [Optimizerâ€™lar ve Ã–ÄŸrenme OranÄ±](#optimizerlar-ve-Ã¶ÄŸrenme-oranÄ±)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-24)
  - [Ä°nteraktif: TensorFlow Playground](#iÌ‡nteraktif-tensorflow-playground)
  - [Iris: Problem TanÄ±mÄ±](#iris-problem-tanÄ±mÄ±)
    - [Ã–zet](#Ã¶zet-28)
    - [Notlar](#notlar-9)
  - [Iris: Veriyi YÃ¼kleme ve BÃ¶lme](#iris-veriyi-yÃ¼kleme-ve-bÃ¶lme)
    - [AdÄ±mlar](#adÄ±mlar)
    - [Ä°puÃ§larÄ±](#iÌ‡puÃ§larÄ±-2)
  - [Iris: Dataset ve DataLoader](#iris-dataset-ve-dataloader)
    - [Ã–zet](#Ã¶zet-29)
    - [Notlar](#notlar-10)
  - [Iris: Model (SimpleClassifier)](#iris-model-simpleclassifier)
    - [Mimari](#mimari)
    - [Ã–nemli Nokta](#Ã¶nemli-nokta)
  - [Iris: EÄŸitim DÃ¶ngÃ¼sÃ¼](#iris-eÄŸitim-dÃ¶ngÃ¼sÃ¼)
    - [Kurulum](#kurulum)
    - [DÃ¶ngÃ¼](#dÃ¶ngÃ¼)
    - [Ä°puÃ§larÄ±](#iÌ‡puÃ§larÄ±-3)
  - [Iris: DeÄŸerlendirme ve DoÄŸruluk](#iris-deÄŸerlendirme-ve-doÄŸruluk)
    - [AdÄ±mlar](#adÄ±mlar-1)
    - [Notlar](#notlar-11)
  - [Iris: Model Kaydetme / YÃ¼kleme](#iris-model-kaydetme--yÃ¼kleme)
    - [KayÄ±t](#kayÄ±t)
    - [YÃ¼kleme](#yÃ¼kleme)
    - [Dikkat](#dikkat)
  - [Ä°kili SÄ±nÄ±flandÄ±rma: Problem ve DÃ¶nÃ¼ÅŸÃ¼m](#iÌ‡kili-sÄ±nÄ±flandÄ±rma-problem-ve-dÃ¶nÃ¼ÅŸÃ¼m)
    - [Ã–zet](#Ã¶zet-30)
    - [DÃ¶nÃ¼ÅŸÃ¼m Ä°lkeleri](#dÃ¶nÃ¼ÅŸÃ¼m-iÌ‡lkeleri)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-25)
  - [Breast Cancer: Veriyi YÃ¼kleme ve BÃ¶lme](#breast-cancer-veriyi-yÃ¼kleme-ve-bÃ¶lme)
    - [AdÄ±mlar](#adÄ±mlar-2)
    - [Not](#not)
  - [Breast Cancer: Dataset ve DataLoader](#breast-cancer-dataset-ve-dataloader)
    - [Ã–zet](#Ã¶zet-31)
    - [Ä°pucu](#iÌ‡pucu)
  - [Breast Cancer: Model (Sigmoid vs Logit)](#breast-cancer-model-sigmoid-vs-logit)
    - [Mimari](#mimari-1)
    - [Neden B Tercih Edilir?](#neden-b-tercih-edilir)
  - [Breast Cancer: EÄŸitim](#breast-cancer-eÄŸitim)
    - [Kurulum](#kurulum-1)
    - [DÃ¶ngÃ¼](#dÃ¶ngÃ¼-1)
    - [SÄ±nÄ±f DengesizliÄŸi](#sÄ±nÄ±f-dengesizliÄŸi)
  - [Breast Cancer: DeÄŸerlendirme ve EÅŸikleme](#breast-cancer-deÄŸerlendirme-ve-eÅŸikleme)
    - [AdÄ±mlar](#adÄ±mlar-3)
    - [Not](#not-1)
  - [Breast Cancer: Tahmin ve Girdi Åekli](#breast-cancer-tahmin-ve-girdi-ÅŸekli)
    - [Not](#not-2)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-26)
  - [MNIST: Veri KÃ¼mesi ve GÃ¶rselleÅŸtirme](#mnist-veri-kÃ¼mesi-ve-gÃ¶rselleÅŸtirme)
    - [Ã–zet](#Ã¶zet-32)
    - [YÃ¼kleme ve Ä°lk GÃ¶rÃ¼ntÃ¼](#yÃ¼kleme-ve-iÌ‡lk-gÃ¶rÃ¼ntÃ¼)
    - [Not](#not-3)
  - [MNIST: DÃ¶nÃ¼ÅŸÃ¼mler (ToTensor, Normalize)](#mnist-dÃ¶nÃ¼ÅŸÃ¼mler-totensor-normalize)
    - [Ã–zet](#Ã¶zet-33)
    - [Ã–rnek](#Ã¶rnek)
  - [MNIST: MLP Baseline (Flatten + FC)](#mnist-mlp-baseline-flatten--fc)
    - [Ã–zet](#Ã¶zet-34)
    - [Mimari](#mimari-2)
    - [Not](#not-4)
  - [MNIST: EÄŸitim ve DeÄŸerlendirme](#mnist-eÄŸitim-ve-deÄŸerlendirme)
    - [EÄŸitim](#eÄŸitim)
    - [DeÄŸerlendirme](#deÄŸerlendirme)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-27)
  - [GPU KullanÄ±mÄ± (CUDA vs CPU)](#gpu-kullanÄ±mÄ±-cuda-vs-cpu)
    - [AdÄ±mlar](#adÄ±mlar-4)
    - [Not](#not-5)
  - [Neden MLP GÃ¶rÃ¼ntÃ¼ler Ä°Ã§in Ä°deal DeÄŸil?](#neden-mlp-gÃ¶rÃ¼ntÃ¼ler-iÌ‡Ã§in-iÌ‡deal-deÄŸil)
    - [Ã–zet](#Ã¶zet-35)
    - [Not](#not-6)
  - [Yerel BÃ¶lgeler ve Sezgi](#yerel-bÃ¶lgeler-ve-sezgi)
    - [Ã–zet](#Ã¶zet-36)
  - [CNN: EvriÅŸimli Katmanlar ve AÄŸÄ±rlÄ±k PaylaÅŸÄ±mÄ±](#cnn-evriÅŸimli-katmanlar-ve-aÄŸÄ±rlÄ±k-paylaÅŸÄ±mÄ±)
    - [Ã–zet](#Ã¶zet-37)
    - [Notlar](#notlar-12)
  - [CNN: Stride ve Padding](#cnn-stride-ve-padding)
    - [Kavramlar](#kavramlar)
    - [Ã‡Ä±kÄ±ÅŸ Boyutu](#Ã§Ä±kÄ±ÅŸ-boyutu)
  - [CNN: Normalizasyon KatmanlarÄ±](#cnn-normalizasyon-katmanlarÄ±)
    - [Ã–zet](#Ã¶zet-38)
    - [FormÃ¼l (BatchNorm, kanal baÅŸÄ±na)](#formÃ¼l-batchnorm-kanal-baÅŸÄ±na)
  - [CNN: Havuzlama (Pooling)](#cnn-havuzlama-pooling)
    - [Ã–zet](#Ã¶zet-39)
    - [Not](#not-7)
  - [CNN: Flatten ve Dropout](#cnn-flatten-ve-dropout)
    - [Ã–zet](#Ã¶zet-40)
  - [CNN: Basit Mimari AkÄ±ÅŸÄ± (MNIST)](#cnn-basit-mimari-akÄ±ÅŸÄ±-mnist)
    - [AkÄ±ÅŸ](#akÄ±ÅŸ)
    - [Notlar](#notlar-13)
  - [Regresyon: Problem ve DÃ¶nÃ¼ÅŸÃ¼m](#regresyon-problem-ve-dÃ¶nÃ¼ÅŸÃ¼m)
    - [Ã–zet](#Ã¶zet-41)
    - [DÃ¶nÃ¼ÅŸÃ¼m Ä°lkeleri](#dÃ¶nÃ¼ÅŸÃ¼m-iÌ‡lkeleri-1)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-28)
  - [Diabetes: Veriyi YÃ¼kleme ve BÃ¶lme](#diabetes-veriyi-yÃ¼kleme-ve-bÃ¶lme)
    - [AdÄ±mlar](#adÄ±mlar-5)
    - [Ä°pucu](#iÌ‡pucu-1)
  - [Diabetes: Dataset ve DataLoader](#diabetes-dataset-ve-dataloader)
    - [Ã–zet](#Ã¶zet-42)
    - [Not](#not-8)
  - [Diabetes: Model (Lineer Ã‡Ä±kÄ±ÅŸ)](#diabetes-model-lineer-Ã§Ä±kÄ±ÅŸ)
    - [Mimari](#mimari-3)
    - [Not](#not-9)
  - [Diabetes: EÄŸitim](#diabetes-eÄŸitim)
    - [Kurulum](#kurulum-2)
    - [DÃ¶ngÃ¼](#dÃ¶ngÃ¼-2)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-29)
  - [Diabetes: DeÄŸerlendirme (MSE/RMSE)](#diabetes-deÄŸerlendirme-msermse)
    - [FormÃ¼ller](#formÃ¼ller)
    - [Uygulama Notu](#uygulama-notu)
  - [Dijital GÃ¶rÃ¼ntÃ¼: Temel TÃ¼rler](#dijital-gÃ¶rÃ¼ntÃ¼-temel-tÃ¼rler)
    - [Ã–zet](#Ã¶zet-43)
    - [KarÅŸÄ±laÅŸtÄ±rma](#karÅŸÄ±laÅŸtÄ±rma)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-30)
  - [Ä°kili (Binary) GÃ¶rÃ¼ntÃ¼](#iÌ‡kili-binary-gÃ¶rÃ¼ntÃ¼)
    - [Ã–zet](#Ã¶zet-44)
    - [KullanÄ±mlar](#kullanÄ±mlar)
    - [Notlar](#notlar-14)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-31)
  - [Gri Seviyeli GÃ¶rÃ¼ntÃ¼](#gri-seviyeli-gÃ¶rÃ¼ntÃ¼)
    - [Ã–zet](#Ã¶zet-45)
    - [Bit DerinliÄŸi](#bit-derinliÄŸi)
    - [Notlar](#notlar-15)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-32)
  - [Renkli GÃ¶rÃ¼ntÃ¼ (RGB)](#renkli-gÃ¶rÃ¼ntÃ¼-rgb)
    - [Ã–zet](#Ã¶zet-46)
    - [Temsil ve Boyutlar](#temsil-ve-boyutlar)
    - [Notlar](#notlar-16)
    - [HÄ±zlÄ± Sorular](#hÄ±zlÄ±-sorular-33)

## ğŸ§­ SÄ±nav KonularÄ± Ä°ndeksi

### ğŸ§  1. Temel TanÄ±mlar (AI, ML, DL, YSA)

* [GiriÅŸ: Yapay Zeka, Makine Ã–ÄŸrenmesi, Derin Ã–ÄŸrenme](#giriÅŸ-yapay-zeka-makine-Ã¶ÄŸrenmesi-derin-Ã¶ÄŸrenme)
* [Yapay Sinir AÄŸlarÄ±: TanÄ±m ve BileÅŸenler](#yapay-sinir-aÄŸlarÄ±-tanÄ±m-ve-bileÅŸenler)
* [NÃ¶ron Aktivasyonu ve Hesaplama](#nÃ¶ron-aktivasyonu-ve-hesaplama)

---

### âš–ï¸ 2. Makine Ã–ÄŸrenmesi vs. Derin Ã–ÄŸrenme

* [Makine Ã–ÄŸrenmesi vs Derin Ã–ÄŸrenme: KarÅŸÄ±laÅŸtÄ±rma](#makine-Ã¶ÄŸrenmesi-vs-derin-Ã¶ÄŸrenme-karÅŸÄ±laÅŸtÄ±rma)
* [ML vs DL: Kavramlar](#ml-vs-dl-kavramlar)
* [ML vs DL: Ã–zellik Ã‡Ä±karÄ±mÄ±](#ml-vs-dl-Ã¶zellik-Ã§Ä±karÄ±mÄ±)
* [ML vs DL: Veri Ä°htiyacÄ±](#ml-vs-dl-veri-iÌ‡htiyacÄ±)
* [ML vs DL: Model KarmaÅŸÄ±klÄ±ÄŸÄ±](#ml-vs-dl-model-karmaÅŸÄ±klÄ±ÄŸÄ±)

---

### ğŸ§ 3. AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting)

* [AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting): TanÄ±m ve Belirtiler](#aÅŸÄ±rÄ±-Ã¶ÄŸrenme-overfitting-tanÄ±m-ve-belirtiler)
* [AÅŸÄ±rÄ± Ã–ÄŸrenmenin Nedenleri](#aÅŸÄ±rÄ±-Ã¶ÄŸrenmenin-nedenleri)
* [Ã–nleme (Veri OdaklÄ±): Veri ArtÄ±rma](#aÅŸÄ±rÄ±-Ã¶ÄŸrenmeyi-Ã¶nleme-veri-odaklÄ±)
* [Ã–nleme (Model OdaklÄ±): Kapasite Azaltma](#aÅŸÄ±rÄ±-Ã¶ÄŸrenmeyi-Ã¶nleme-model-odaklÄ±)
* [Ã–nleme (DÃ¼zenlileÅŸtirme): Dropout, L1/L2 (Weight Decay)](#dÃ¼zenlileÅŸtirme-dropout-l1l2-weight-decay)
* [Ã–nleme: Erken Durdurma ve Batch Normalization](#erken-durdurma-ve-batch-normalization)

---

### ğŸ–¼ï¸ 4. CNN ve Max Pooling Ne Yapar?

* [Neden MLP GÃ¶rÃ¼ntÃ¼ler Ä°Ã§in Ä°deal DeÄŸil?](#neden-mlp-gÃ¶rÃ¼ntÃ¼ler-iÌ‡Ã§in-iÌ‡deal-deÄŸil)
* [CNN: EvriÅŸimli Katmanlar ve AÄŸÄ±rlÄ±k PaylaÅŸÄ±mÄ±](#cnn-evriÅŸimli-katmanlar-ve-aÄŸÄ±rlÄ±k-paylaÅŸÄ±mÄ±)
* [HiyerarÅŸik Temsil Ã–ÄŸrenimi (CNN nasÄ±l Ã¶ÄŸrenir)](#hiyerarÅŸik-temsil-Ã¶ÄŸrenimi)
* [CNN: Havuzlama (Pooling) (Max Pooling nedir?)](#cnn-havuzlama-pooling)

---

### ğŸ§± 5. Katman TÃ¼rleri ve DiÄŸer Temel TanÄ±mlar

* **Aktivasyonlar:**
    * [Aktivasyon FonksiyonlarÄ±: Lineer, Sigmoid, Tanh, ReLU](#aktivasyon-fonksiyonlarÄ±-lineer-sigmoid-tanh-relu)
    * [ReLU ve Seyrek Aktivite](#relu-ve-seyrek-aktivite)
    * [Softmax Aktivasyonu ve Ã–zellikleri](#softmax-aktivasyonu-ve-Ã¶zellikleri)
* **DiÄŸer Katmanlar:**
    * [CNN: Stride ve Padding](#cnn-stride-ve-padding)
    * [CNN: Normalizasyon KatmanlarÄ± (Batch Norm)](#cnn-normalizasyon-katmanlarÄ±)
    * [CNN: Flatten ve Dropout](#cnn-flatten-ve-dropout)
* **EÄŸitim SÃ¼reci:**
    * [Train/Validation/Test: Neden ve NasÄ±l?](#trainvalidationtest-neden-ve-nasÄ±l)
    * [KayÄ±p FonksiyonlarÄ± (MSE, Cross Entropy)](#kayÄ±p-fonksiyonlarÄ±-ve-toplam-kayÄ±p)
    * [EÄŸitim SÃ¼reci ve Optimizasyon (Epoch, Batch, Optimizer)](#eÄŸitim-sÃ¼reci-ve-optimizasyon)
* **DiÄŸer Mimari Kavramlar:**
    * [Derin AÄŸlarda Gradyan SorunlarÄ± (Vanishing/Exploding)](#derin-aÄŸlarda-gradyan-sorunlarÄ±)
    * [ResNet: Residual BaÄŸlantÄ±lar](#resnet-residual-baÄŸlantÄ±lar)
    * [Transfer Ã–ÄŸrenme: Genel BakÄ±ÅŸ](#transfer-Ã¶ÄŸrenme-genel-bakÄ±ÅŸ)

<a id="giris-yz-ml-dl"></a>

## GiriÅŸ: Yapay Zeka, Makine Ã–ÄŸrenmesi, Derin Ã–ÄŸrenme

### Ã–zet

- Yapay Zeka (YZ): Ä°nsan zekasÄ±na benzer iÅŸlevleri (Ã¶ÄŸrenme, problem Ã§Ã¶zme, Ã¶rÃ¼ntÃ¼ tanÄ±ma) bilgisayarlara kazandÄ±rmayÄ± amaÃ§layan alan.
- Makine Ã–ÄŸrenmesi (MÃ–): YZ'nin bir alt dalÄ±; sistemlerin veriden Ã¶rÃ¼ntÃ¼ler Ã¶ÄŸrenerek insan mÃ¼dahalesi olmadan performansÄ±nÄ± geliÅŸtirmesi ve geleceÄŸe yÃ¶nelik tahminler yapmasÄ±.
- Derin Ã–ÄŸrenme (DÃ–): Ã‡ok katmanlÄ± (derin) hesaplama modelleriyle veri temsillerini kademeli soyutlama seviyelerinde otomatik Ã¶ÄŸrenen yÃ¶ntemler sÄ±nÄ±fÄ±.

> "Derin Ã¶ÄŸrenme, birden fazla iÅŸleme katmanÄ±ndan oluÅŸan hesaplama modellerinin, verinin Ã§oklu soyutlama seviyelerinde gÃ¶sterimlerini Ã¶ÄŸrenmesine olanak tanÄ±r." â€” Yann LeCun, Yoshua Bengio, Geoff Hinton

### Temel Kavramlar

- Yapay Zeka
    - AmaÃ§: BiliÅŸsel kabiliyetlerin otomasyonu (akÄ±l yÃ¼rÃ¼tme, planlama, algÄ±, Ã¶ÄŸrenme).
    - YaklaÅŸÄ±mlar: Kural tabanlÄ± sistemler, arama/optimizasyon, Ã¶ÄŸrenmeye dayalÄ± yÃ¶ntemler.

- Makine Ã–ÄŸrenmesi
    - TanÄ±m: Veriye dayalÄ± Ã¶ÄŸrenme; modeller Ã¶rÃ¼ntÃ¼leri keÅŸfeder ve tahmin Ã¼retir.
    - Ã‡Ä±ktÄ±: SÄ±nÄ±flandÄ±rma, regresyon, sÄ±ralama, kÃ¼meleme vb. (bu sayfada aÄŸÄ±rlÄ±kla tahmine vurgu yapÄ±lmÄ±ÅŸtÄ±r).

- Derin Ã–ÄŸrenme
    - Ã–z: Temsili Ã¶ÄŸrenme; Ã¶zelliklerin elle Ã§Ä±karÄ±lmasÄ± yerine aÄŸÄ±n katmanlarÄ± tarafÄ±ndan otomatik Ã¶ÄŸrenilmesi.
    - Avantaj: BÃ¼yÃ¼k veri ve hesaplama ile karmaÅŸÄ±k Ã¶rÃ¼ntÃ¼leri Ã¶ÄŸrenebilme.

### Ä°puÃ§larÄ± / Notlar

- Ä°liÅŸki: DÃ– âŠ‚ MÃ– âŠ‚ YZ. Derin Ã¶ÄŸrenme, makine Ã¶ÄŸrenmesinin bir alt kÃ¼mesidir; makine Ã¶ÄŸrenmesi de yapay zekanÄ±n alt kÃ¼mesidir.
 - DÃ–'nÃ¼n gÃ¼cÃ¼: Ã‡ok katmanlÄ± mimarilerle (derinlik) temsil gÃ¼cÃ¼ artar; yeterli veri ve hesaplama kritik faktÃ¶rlerdir.
- GÃ¶rseller (#1.jpg, #2.jpg) bu bÃ¶lÃ¼mde metinsel olarak Ã¶zetlenmiÅŸtir.

### HÄ±zlÄ± Sorular

1) MÃ–'nÃ¼n YZ iÃ§indeki yeri nedir?
2) Derin Ã¶ÄŸrenmeyi makine Ã¶ÄŸrenmesinden ayÄ±ran temel Ã¶zellik nedir?
3) YZ'nin baÅŸlÄ±ca hedeflediÄŸi biliÅŸsel kabiliyetlerden Ã¼Ã§Ã¼ hangileridir?

<a id="ml-vs-dl"></a>

## Makine Ã–ÄŸrenmesi vs Derin Ã–ÄŸrenme: KarÅŸÄ±laÅŸtÄ±rma

### Ã–zet

- Makine Ã–ÄŸrenmesi (ML): Ä°nsan tarafÄ±ndan tasarlanan Ã¶zellikleri (feature engineering) kullanÄ±r; daha az veriyle ve daha basit modellerle iyi genelleme yapabilir.
- Derin Ã–ÄŸrenme (DL): Ã–zellikleri ham veriden otomatik Ã¶ÄŸrenir (temsili Ã¶ÄŸrenme); Ã§ok veri ve hesaplama gÃ¼cÃ¼ ile Ã¼stÃ¼n performans saÄŸlar.

### Ä°puÃ§larÄ± / Notlar

- Az veri + aÃ§Ä±klanabilirlik Ã¶nceliÄŸi: ML genellikle daha uygundur (lojistik regresyon, karar aÄŸaÃ§larÄ±, SVM, RF).
- BÃ¼yÃ¼k veri + ham sinyaller (gÃ¶rÃ¼ntÃ¼/ses/metin): DL (CNN/RNN/Transformer) uÃ§tan uca temsillerle daha iyi sonuÃ§ verir.

### HÄ±zlÄ± Sorular

1) Hangi durumda elle Ã¶zellik Ã§Ä±karÄ±mÄ± yerine otomatik temsili Ã¶ÄŸrenim tercih edilir?
2) KÃ¼Ã§Ã¼k veri kÃ¼melerinde aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi azaltmak iÃ§in hangi iki yaklaÅŸÄ±mÄ± kullanÄ±rsÄ±nÄ±z?

<a id="ml-dl-kavramlar"></a>

## ML vs DL: Kavramlar

- Makine Ã–ÄŸrenmesi (ML): Veriden Ã¶rÃ¼ntÃ¼ Ã¶ÄŸrenen yÃ¶ntemler ailesi; Ã¶zellikler genellikle insan tarafÄ±ndan tanÄ±mlanÄ±r.
- Derin Ã–ÄŸrenme (DL): MLâ€™nin alt alanÄ±; Ã§ok katmanlÄ± yapay sinir aÄŸlarÄ± ile Ã¶zellikleri ve karar fonksiyonunu birlikte Ã¶ÄŸrenir.

<a id="ml-dl-ozellik"></a>

## ML vs DL: Ã–zellik Ã‡Ä±karÄ±mÄ±

- ML: Ã–zellik Ã§Ä±karÄ±mÄ± elle/uzman bilgisiyle yapÄ±lÄ±r.
    - Ã–rnek (gÃ¶rÃ¼ntÃ¼): Kenar, renk histogramÄ±, doku tanÄ±mlayÄ±cÄ±larÄ± Ã§Ä±karÄ±lÄ±p SVM/LogRegâ€™e verilir.
- DL: Ã–zellik Ã§Ä±karÄ±mÄ± otomatik; aÄŸ katmanlarÄ± ham piksellerden kenarâ†’dokuâ†’ÅŸekilâ†’nesne hiyerarÅŸisini kendisi Ã¶ÄŸrenir (CNN).

<a id="ml-dl-veri"></a>

## ML vs DL: Veri Ä°htiyacÄ±

- ML: Az/orta Ã¶lÃ§ekli veri ile makul sonuÃ§lar; kÃ¼Ã§Ã¼k veriyle iyi genelleme potansiyeli.
- DL: YÃ¼ksek kapasite nedeniyle bÃ¼yÃ¼k veri (binlerceâ€“milyonlarca Ã¶rnek) gereksinimi; kÃ¼Ã§Ã¼k veride overfitting riski yÃ¼ksek, dÃ¼zenlileÅŸtirme/aktar. Ã¶ÄŸrenme faydalÄ±dÄ±r.

<a id="ml-dl-karmasiklik"></a>

## ML vs DL: Model KarmaÅŸÄ±klÄ±ÄŸÄ±

- ML: Daha basit istatistiksel/Ã¶ÄŸrenme modelleri (Regresyon, Karar AÄŸacÄ±, SVM, KNN, RF, GBM vb.). Parametre sayÄ±sÄ± gÃ¶rece azdÄ±r.
- DL: Ã‡ok katmanlÄ± sinir aÄŸlarÄ± (CNN, RNN/LSTM, Transformer vb.); parametre sayÄ±sÄ± milyonlarâ€“milyarlar olabilir.

<a id="ml-dl-donanim"></a>

## ML vs DL: DonanÄ±m ve Hesaplama

- ML: CPU Ã§oÄŸu zaman yeterlidir; eÄŸitim genelde hÄ±zlÄ±dÄ±r.
- DL: GPU/TPU gibi hÄ±zlandÄ±rÄ±cÄ±lar gerektirir; eÄŸitim daha uzun ve hesaplama yoÄŸun olabilir.

<a id="ml-dl-uygulamalar"></a>

## ML vs DL: Uygulama Ã–rnekleri

- GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme
    - ML: Elle Ã§Ä±karÄ±lmÄ±ÅŸ kenar/renk/doku + SVM/RF.
    - DL: CNN, ResNet, YOLO, U-Net.
- DoÄŸal Dil Ä°ÅŸleme
    - ML: TF-IDF/BoW + Naive Bayes/SVM.
    - DL: Transformer, BERT, GPT.
- Ses TanÄ±ma
    - ML: MFCC + HMM/GM.
    - DL: RNN/LSTM, Wav2Vec, Conformer.
- TÄ±p/Biyomedikal
    - ML: Klinik tablolardan RF/GBM.
    - DL: Ultrason/MRI/CT analizi iÃ§in CNN/U-Net; segmentasyon/sÄ±nÄ±flandÄ±rma.

<a id="ai-tarihce-1943-2009"></a>

## Yapay ZekanÄ±n TarihÃ§esi (1943â€“2009)

### Ã–zet

- Sinirsel hesaplama (McCullochâ€“Pitts) ile baÅŸlayan Ã§izgi; perceptron, geri yayÄ±lÄ±m, CNN'ler, SVM, LSTM ve bÃ¼yÃ¼k veri kÃ¼meleri (ImageNet) ile ivme kazanmÄ±ÅŸtÄ±r.

### Zaman Ã‡izelgesi (SeÃ§me BaÅŸlÄ±klar)

- 1943 â€” McCulloch & Pitts: Sinir aÄŸlarÄ±na dayalÄ± ilk matematiksel model; nÃ¶ronlar mantÄ±k kapÄ±larÄ± (AND/OR/NOT) gibi; ikili girdiler, eÅŸik aÅŸÄ±ldÄ±ÄŸÄ±nda 1, aksi halde 0 Ã¼retir.
- 1950 â€” Alan Turing: Makine zekÃ¢sÄ±nÄ± tartÄ±ÅŸÄ±r; Turing Testi fikrini ortaya koyar.
- 1952 â€” Arthur Samuel: Dama iÃ§in ilk makine Ã¶ÄŸrenmesi programÄ±.
- 1957 â€” Frank Rosenblatt: Perceptron fikri; optik bir "beyin" inÅŸasÄ± vizyonu.
- 1959 â€” Hubel & Wiesel: GÃ¶rsel kortekste yalÄ±n ve karmaÅŸÄ±k hÃ¼creler; yapay sinir aÄŸlarÄ±na ilham.
- 1960 â€” Henry J. Kelley: Kontrol kuramÄ±; AI ve sinir aÄŸlarÄ±na uygulamalar.
- 1965 â€” Ivakhnenko & Lapa: Ä°lk Ã§alÄ±ÅŸan derin (Ã§ok katmanlÄ±) Ã¶ÄŸrenme aÄŸlarÄ±.
- 1979â€“80 â€” Kunihiko Fukushima: Neocognitron; modern CNN'lere Ã¶ncÃ¼l mimari.
- 1982 â€” John Hopfield: Hopfield aÄŸlarÄ±; iliÅŸkilendirilebilir bellek olarak tekrarlayan aÄŸlar.
- 1985 â€” Terry Sejnowski: NETtalk; yazÄ±lÄ± kelimelerin telaffuzunu Ã¶ÄŸrenir.
- 1986 â€” Rumelhart, Hinton, Williams: Geri yayÄ±lÄ±m (backpropagation) sÃ¼recinin ayrÄ±ntÄ±larÄ±; eÄŸitilebilir Ã§ok katmanlÄ± aÄŸlar.
- 1989 â€” Yann LeCun: CNN'lerle el yazÄ±sÄ± rakam tanÄ±ma; Ã§ek/posta kodu okuma uygulamalarÄ±.
- 1993 â€” JÃ¼rgen Schmidhuber: Tekrarlayan sinir aÄŸlarÄ±nda derin Ã¶ÄŸrenme gÃ¶revleri.
- 1995 â€” Cortes & Vapnik: Destek VektÃ¶r Makineleri (SVM); metin sÄ±nÄ±flandÄ±rma, el yazÄ±sÄ± tanÄ±ma vb.
- 1997 â€” Hochreiter & Schmidhuber: LSTM; RNN'lerde uzun baÄŸÄ±mlÄ±lÄ±klarÄ±n Ã¶ÄŸrenilmesi.
- 1998 â€” Yann LeCun: Gradyan tabanlÄ± Ã¶ÄŸrenmeye vurgu; derin Ã¶ÄŸrenmede tercih edilen yaklaÅŸÄ±m.
- 2009 â€” Fei-Fei Li: ImageNet; etiketli bÃ¼yÃ¼k gÃ¶rsel veri tabanÄ± ile derin Ã¶ÄŸrenmenin atÄ±lÄ±m zemini.

### KavÅŸak NoktalarÄ± (Detay)

- 1943: McCullochâ€“Pitts NÃ¶ronu
    - Ä°kili girdileri toplayan eÅŸik birimi; mantÄ±k kapÄ±larÄ±yla benzeÅŸim.
    - Basit ama yapay sinir aÄŸlarÄ±nÄ±n temel soyut modeli.

- 1958: Rosenblatt'Ä±n Perceptron Modeli
    - Tek nÃ¶ronlu hesaplama modeli; ikili sÄ±nÄ±flandÄ±rma yapar.
    - Basit bir eÄŸitim algoritmasÄ±na sahiptir; donanÄ±m Ã¼zerinde de inÅŸa edilmiÅŸtir.

- 1969: Minsky & Papert'in EleÅŸtirisi
    - Perceptron'lar yalnÄ±zca doÄŸrusal ayrÄ±labilir fonksiyonlarÄ± temsil eder; XOR Ã¶rneÄŸiyle sÄ±nÄ±rlÄ±lÄ±k.
    - Bu eleÅŸtiriler sÄ±klÄ±kla "AI Winter" ile iliÅŸkilendirilse de, dÃ¶nemsel finansman/ilgi dÃ¼ÅŸÃ¼ÅŸÃ¼nÃ¼n tek nedeni deÄŸildir.

### HÄ±zlÄ± Sorular

1) Perceptron neden XOR problemini Ã§Ã¶zemiyor?
2) Geri yayÄ±lÄ±mÄ±n (1986) Ã§ok katmanlÄ± aÄŸlar iÃ§in Ã¶nemi nedir?
3) Hangi geliÅŸme(ler) CNN'lerin pratik baÅŸarÄ±sÄ±nÄ± tetikledi (ipucu: Hubel & Wiesel, Neocognitron, LeCun)?

<a id="ai-1990lar"></a>

## 1990'lar: MLP, Backprop, BPTT, CNN, LSTM

### Ã–zet

- 1990'larda Ã§ok katmanlÄ± perceptronlar (MLP) ve geri yayÄ±lÄ±m (Backprop) ile teorik/pratik ilerlemeler yaÅŸandÄ±; RNN'ler iÃ§in BPTT, CNN ve LSTM gibi mimariler tanÄ±tÄ±ldÄ±.

### Temel Noktalar

- Evrensel YakÄ±nsama: Ã‡ok katmanlÄ± perceptronlar yeterli geniÅŸlik/derinlikle herhangi bir sÃ¼rekli fonksiyonu yaklaÅŸÄ±klar (Cybenko, 1989; Hornik, 1991).
- EÄŸitim AlgoritmalarÄ±: Geriye YayÄ±lÄ±m (Rumelhart, Hinton, Williams, 1986), Zaman Boyunca Geriye YayÄ±lÄ±m (Werbos, 1988).
- Mimariler: CNN (LeCun ve ark., 1989) gÃ¶rÃ¼ntÃ¼lerde yerel duyarlÄ±lÄ±k ve paylaÅŸÄ±mlÄ± aÄŸÄ±rlÄ±klarla verimli; LSTM (Hochreiter & Schmidhuber, 1997) uzun-baÄŸÄ±mlÄ±lÄ±k sorununu hafifletir.

### HÄ±zlÄ± Sorular

1) BPTT hangi problem sÄ±nÄ±fÄ± iÃ§in gereklidir?
2) CNN'in iki temel fikrini sayÄ±n: yerel alÄ±cÄ± alanlar ve ...?
3) Neden LSTM, vanishing gradient sorununa bir Ã§Ã¶zÃ¼m sayÄ±lÄ±r?

<a id="dl-neden-zorlandi"></a>

## Erken DÃ¶nem: Neden BaÅŸarÄ±sÄ±z Oldu?

### Ã–zet

- Veri ve hesaplama yetersizliÄŸi, el yapÄ±mÄ± Ã¶zelliklere baÄŸÄ±mlÄ±lÄ±k ve optimizasyon/yorumlanabilirlik kaygÄ±larÄ± nedeniyle derin aÄŸlar uzun sÃ¼re yaygÄ±nlaÅŸamadÄ±; SVM gibi yÃ¶ntemler Ã¶ne Ã§Ä±ktÄ±.

### Ana GerekÃ§eler

- Az Veride Ã‡ok Parametre: Etiketli Ã¶rnek sayÄ±sÄ± kÃ¼Ã§Ã¼kken Ã§ok sayÄ±da parametreyi Ã¶ÄŸrenmek zor; aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) riski yÃ¼ksek.
- BÃ¼yÃ¼k Veri ve GPU EksikliÄŸi: YaygÄ±n bÃ¼yÃ¼k veri kÃ¼meleri ve hÄ±zlandÄ±rÄ±cÄ± donanÄ±m (GPU) eriÅŸimi sÄ±nÄ±rlÄ±ydÄ±; eÄŸitim Ã§ok yavaÅŸtÄ±.
- El YapÄ±mÄ± Ã–zellikler: DÃ¶nemin yaklaÅŸÄ±mÄ±, hand-crafted feature'lar tasarlayÄ±p klasik MÃ– algoritmalarÄ±na vermekti; temsil Ã¶ÄŸrenimi zayÄ±f kaldÄ±.
- DÄ±ÅŸbÃ¼key Olmayan Optimizasyon: KayÄ±p fonksiyonu Ã§ok tepe/Ã§ukur iÃ§erir; yerel minimumlara takÄ±lma ve eÄŸitim kararsÄ±zlÄ±ÄŸÄ± kaygÄ±larÄ±.
- Yorumlanabilirlik: "Kara kutu" algÄ±sÄ± gÃ¼ven sorunlarÄ±na yol aÃ§tÄ± (tÄ±p/finans gibi alanlarda).
- SVM'nin BaÅŸarÄ±sÄ±: DÄ±ÅŸbÃ¼key optimizasyon ve gÃ¼Ã§lÃ¼ genelleme; az veriyle hÄ±zlÄ± ve saÄŸlam sonuÃ§lar (Cortes & Vapnik, 1995).

### Notlar

- Non-konveksite tek baÅŸÄ±na engel deÄŸildir; iyi baÅŸlatma, normalizasyon ve optimizasyon teknikleriyle pratikte aÅŸÄ±labilir. Ancak 1990'larda ekosistem hazÄ±r deÄŸildi.

### HÄ±zlÄ± Sorular

1) Erken dÃ¶nemde derin Ã¶ÄŸrenmeye karÅŸÄ± SVM neden cazipti?
2) El yapÄ±mÄ± Ã¶zellikler ile temsil Ã¶ÄŸrenimi arasÄ±ndaki fark nedir?
3) Non-konveks optimizasyonda pratikte hangi teknikler yardÄ±mcÄ± olur? (ipucu: initialization, normalization, optimizers)

<a id="lenet-1998"></a>

## Derin Ã–ÄŸrenme: LeNet (1998) ve CNN'ler

### Ã–zet

- Yann LeCun ve ekibi 1998'de gradyan-temelli CNN (LeNet) ile el yazÄ±sÄ± rakam tanÄ±mada yÃ¼ksek baÅŸarÄ± gÃ¶sterdi; uygulamalar Ã§ek/posta kodu okumaya yayÄ±ldÄ±.

### LeNet'in Temelleri

- GÃ¶rev: 0â€“9 rakamlarÄ±nÄ±n sÄ±nÄ±flandÄ±rÄ±lmasÄ± (MNIST benzeri).
- Ã‡Ä±ktÄ±: Her sÄ±nÄ±f iÃ§in olasÄ±lÄ±k tahmini; en yÃ¼ksek olasÄ±lÄ±k etiket olarak seÃ§ilir.
- YaklaÅŸÄ±m: EvriÅŸim + havuzlama + tam baÄŸlÄ± katmanlar; paylaÅŸÄ±mlÄ± aÄŸÄ±rlÄ±klar ve yerel alÄ±cÄ± alanlar ile parametre verimliliÄŸi.
- Ã–lÃ§ek: YaklaÅŸÄ±k ~60.000 parametre; dÃ¶nem donanÄ±mÄ± nedeniyle daha bÃ¼yÃ¼k problemlere Ã¶lÃ§eklenmesi zordu.

### Neden SÄ±nÄ±rlÄ± KaldÄ± (O DÃ¶nem)?

- DÃ¼ÅŸÃ¼k Hesaplama Kapasitesi: GeniÅŸ/deep CNN'lerin eÄŸitimi pratik deÄŸildi; eÄŸitim sÃ¼releri gÃ¼nler/haftalar sÃ¼rebiliyordu.
- Veri KÄ±tlÄ±ÄŸÄ±: BÃ¼yÃ¼k, etiketli veri kÃ¼meleri sÄ±nÄ±rlÄ±ydÄ±; genelleme gÃ¼Ã§leÅŸiyordu.

### Notlar

- GÃ¶rseller (#3.jpg, #4.jpg, #5.jpg) eriÅŸilemediÄŸi iÃ§in aÃ§Ä±klamalar metne iÅŸlenmiÅŸtir.

### HÄ±zlÄ± Sorular

1) LeNet'in iki ana bileÅŸeni nedir (katman dÃ¼zeyinde)?
2) PaylaÅŸÄ±mlÄ± aÄŸÄ±rlÄ±klar neden Ã¶nemlidir?
3) 1998'de LeNet'in geniÅŸ Ã¶lÃ§ekli problemlerde sÄ±nÄ±rlÄ± kalmasÄ±nÄ±n iki nedeni?

<a id="imagenet-ilsvrc"></a>

## ImageNet ve ILSVRC (2009â€“2012)

### Ã–zet

- Derin Ã¶ÄŸrenmenin sÄ±Ã§rama yapmasÄ± iÃ§in hesaplama gÃ¼cÃ¼nÃ¼n yanÄ±nda geniÅŸ, etiketli veri setlerine ihtiyaÃ§ vardÄ±. 2009'da kÃ¼resel destekle oluÅŸturulan ImageNet, bu ihtiyacÄ± karÅŸÄ±ladÄ±.

### Temel Noktalar

- ImageNet (2009): 22 binin Ã¼zerinde kategori ve milyonlarca etiketli gÃ¶rÃ¼ntÃ¼; geniÅŸ Ã¶lÃ§ekli gÃ¶rsel tanÄ±ma araÅŸtÄ±rmalarÄ± iÃ§in standart.
- ILSVRC (2012): ImageNet tabanlÄ± yÄ±llÄ±k yarÄ±ÅŸma; sÄ±nÄ±flandÄ±rma ve nesne tanÄ±ma gÃ¶revleri iÃ§in kÄ±yaslama ortamÄ±.

### HÄ±zlÄ± Sorular

1) Neden â€œbÃ¼yÃ¼k, etiketli veriâ€ derin Ã¶ÄŸrenme iÃ§in kritik?
2) ILSVRCâ€™nin araÅŸtÄ±rma topluluÄŸuna saÄŸladÄ±ÄŸÄ± iki fayda nedir?

<a id="alexnet-2012"></a>

## AlexNet (2012): BaÅŸarÄ± ve Yenilikler

### Ã–zet

- 2012 ILSVRC'de AlexNetâ€™in baÅŸarÄ±sÄ±, CNN ve derin Ã¶ÄŸrenmeye ilgiyi yeniden canlandÄ±rdÄ±; mimari LeNetâ€™e benzer olsa da derinlik, Ã¶lÃ§ek ve modern tekniklerle Ã§arpÄ±cÄ± bir fark yarattÄ±.

### Mimari ve Ã–lÃ§ek

- Katmanlar: 7 gizli katman (bazÄ± max pooling katmanlarÄ± sayÄ±lmazsa).
- Parametreler: ~60 milyon.
- Ekip: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton.

### Ã–ne Ã‡Ä±kan Teknikler

- ReLU aktivasyonlarÄ±: DoÄŸrusal doÄŸrultulmuÅŸ birimler ile gradyanlarÄ±n sÃ¶nÃ¼m sorunlarÄ±na karÅŸÄ± pratik avantaj.
- Veri artÄ±rma (data augmentation): DÃ¶nÃ¼ÅŸÃ¼m/bozulmalarla daha iyi genelleme.
- Dropout: Tam baÄŸlÄ± katmanlarda aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi azaltma.

### Notlar

- LeNet ile benzer prensipler (evriÅŸim + havuzlama + tam baÄŸlÄ±) daha derin ve geniÅŸ Ã¶lÃ§ekte uygulanmÄ±ÅŸtÄ±r.

### HÄ±zlÄ± Sorular

1) AlexNetâ€™in baÅŸarÄ±sÄ±nda en kritik iki dÃ¼zenlileÅŸtirme tekniÄŸi nedir?
2) ReLUâ€™nun sigmoid/tanhâ€™a gÃ¶re iki avantajÄ±nÄ± sÃ¶yleyin.

<a id="alexnet-inference"></a>

### AlexNet: Torchvision ile Ã‡Ä±karÄ±m (GÃ¼ncel API)

- Mimari Ã¶zeti: 8 katman (5Ã—Conv + 3Ã—FC), â‰ˆ60M parametre.
- 2012 ILSVRCâ€™de geleneksel yÃ¶ntemlere bÃ¼yÃ¼k fark atarak â€œImageNet devriminiâ€ baÅŸlatmÄ±ÅŸtÄ±r.

PyTorch/Torchvisionâ€™da Ã¶nceden eÄŸitilmiÅŸ AlexNetâ€™i kullanmanÄ±n gÃ¼ncel yolu, aÄŸÄ±rlÄ±k (weights) APIâ€™sidir. `pretrained=True` artÄ±k kullanÄ±mdan kalkmÄ±ÅŸtÄ±r (deprecated).

- Ã–nerilen kullanÄ±m:
    - AÄŸÄ±rlÄ±klar ve dÃ¶nÃ¼ÅŸtÃ¼rmeler: `AlexNet_Weights.IMAGENET1K_V1`
    - SÄ±nÄ±f adlarÄ±: `weights.meta['categories']`

Ã–rnek (Ã§Ä±karÄ±m):

```python
import torch
from PIL import Image
from torchvision.models import alexnet, AlexNet_Weights

# 1) Model ve aÄŸÄ±rlÄ±klar
weights = AlexNet_Weights.IMAGENET1K_V1
model = alexnet(weights=weights)
model.eval()

# 2) DÃ¶nÃ¼ÅŸÃ¼mler (mean/std dahil)
preprocess = weights.transforms()

# 3) GÃ¶rÃ¼ntÃ¼ oku ve hazÄ±rla
img = Image.open('OrnekResimler/kedi.jpg').convert('RGB')
batch = preprocess(img).unsqueeze(0)  # [1,3,224,224]

# 4) Cihaz (varsa GPU)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
batch = batch.to(device)

with torch.no_grad():
        logits = model(batch)
        probs = torch.softmax(logits, dim=1)
        top_p, top_id = probs.topk(1, dim=1)

cls_name = weights.meta['categories'][top_id.item()]
print(f'Tahmin: {cls_name}  olasÄ±lÄ±k={top_p.item():.4f}')
```

Notlar:

- Eski Ã¶rneklerde gÃ¶rÃ¼len `pretrained=True` yerine `weights=AlexNet_Weights.IMAGENET1K_V1` kullanÄ±n.
- Manuel `transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])` doÄŸru olsa da, `weights.transforms()` hatasÄ±z ve gÃ¼ncel Ã¶n-iÅŸlemeyi otomatik verir.
- Harici `imageNetClasses.txt` yerine `weights.meta['categories']` ile sÄ±nÄ±f adlarÄ±nÄ± alÄ±n.

<a id="temsil-hiyerarsi"></a>

<a id="sota-models"></a>

## State-of-the-Art (SOTA) Modeller

### Ã–zet

- SOTA (son teknoloji) modeller, belirli gÃ¶revlerde mevcut en yÃ¼ksek performanslÄ± yaklaÅŸÄ±mlarÄ± temsil eder ve hem akademi hem endÃ¼stride yeni standartlar belirler.
- KÄ±yaslamalar (benchmarks) ve liderlik tablolarÄ± (leaderboards) SOTAâ€™yÄ± gÃ¶rÃ¼nÃ¼r kÄ±lar; SOTA dinamik olarak deÄŸiÅŸir.

### RolÃ¼ ve BaÄŸlam

- AraÅŸtÄ±rma: Yeni mimari/Ã¶ÄŸrenme yÃ¶ntemleri SOTAâ€™yÄ± iteratif olarak yukarÄ± taÅŸÄ±r (Ã¶r. CNN â†’ ResNet â†’ EfficientNet â†’ Vision Transformers).
- ÃœrÃ¼nleÅŸtirme: Veri/bÃ¼tÃ§e/kÄ±sÄ±tlar altÄ±nda SOTA yerine daha hafif modeller (MobileNet, EfficientNet-Lite) tercih edilebilir.

### TemsilÃ® Aileler (BilgisayarlÄ± GÃ¶rÃ¼)

- AlexNet (2012) â†’ VGG/GoogLeNet (2014) â†’ ResNet (2015) â†’ DenseNet, Inception-v4
- MobileNet, ShuffleNet (mobil/edge)
- EfficientNet ailesi (Ã¶lÃ§ekleme prensipleri)
- Vision Transformer (ViT), Swin Transformer, ConvNeXt (CNN/Transformer hibritleri)

### Kaynaklar

- Torchvision Ã¶nceden eÄŸitilmiÅŸ modeller ve performanslarÄ±: https://docs.pytorch.org/vision/main/models.html
    - DokÃ¼mantasyonda, her model iÃ§in giriÅŸ boyutu, normalize deÄŸerleri, top-1/top-5 doÄŸruluk ve `weights` kullanÄ±mÄ± bulunur.

### HÄ±zlÄ± Sorular

1) Neden â€œen iyi doÄŸrulukâ€ her zaman â€œen iyi Ã¼retim modeliâ€ deÄŸildir?
2) Torchvisionâ€™da bir modelin doÄŸru Ã¶n-iÅŸlemesini otomatik almak iÃ§in hangi APIâ€™yi kullanÄ±rsÄ±nÄ±z?

<a id="transfer-ogrenme"></a>

## Transfer Ã–ÄŸrenme: Genel BakÄ±ÅŸ

### Ã–zet

- Transfer Ã¶ÄŸrenme, bÃ¼yÃ¼k ve Ã§eÅŸitli bir kaynak veri kÃ¼mesinde (Ã¶r. ImageNet) Ã¶nceden eÄŸitilen bir modelin, hedef bir gÃ¶rev/veri kÃ¼mesi iÃ§in yeniden kullanÄ±lmasÄ±dÄ±r.
- Ä°ki ana strateji vardÄ±r: Ã–zellik Ã‡Ä±karma (tÃ¼m aÄŸÄ± dondur, yalnÄ±zca son katmanÄ± eÄŸit) ve Ä°nce Ayar (bazÄ±/Ã¼st katmanlarÄ± dÃ¼ÅŸÃ¼k LR ile yeniden eÄŸit).

### Neden Ä°ÅŸe Yarar?

- Alt katmanlar â€œgenelâ€ Ã¶zellikleri (kenar, doku) Ã¶ÄŸrenir; Ã¼st katmanlar daha gÃ¶rev-Ã¶zel temsiller taÅŸÄ±r. Bu nedenle az veriyle de iyi performans saÄŸlanabilir ve eÄŸitim sÃ¼resi kÄ±salÄ±r.

<a id="transfer-feature"></a>

## Transfer: Ã–zellik Ã‡Ä±karma (Feature Extraction)

- Ã–nceden eÄŸitilmiÅŸ modelin tÃ¼m katmanlarÄ± dondurulur (`requires_grad=False`).
- Sadece son sÄ±nÄ±flandÄ±rÄ±cÄ± katman (Ã¶r. `classifier[6]`) hedef sÄ±nÄ±f sayÄ±sÄ±na uyacak ÅŸekilde yeniden tanÄ±mlanÄ±r ve eÄŸitilir.
- Avantaj: HÄ±zlÄ±, aÅŸÄ±rÄ± Ã¶ÄŸrenme riski daha dÃ¼ÅŸÃ¼ktÃ¼r. Dezavantaj: Hedef gÃ¶reve uyum sÄ±nÄ±rlÄ± kalabilir.

<a id="transfer-fine"></a>

## Transfer: Ä°nce Ayar (Fine-Tuning)

- Ã–nceden eÄŸitilmiÅŸ aÄŸÄ±n Ã¼st katmanlarÄ± (veya son konvolÃ¼syon bloÄŸu) Ã§Ã¶zÃ¼lÃ¼r; dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ± ile (Ã¶r. 10Ã— daha kÃ¼Ã§Ã¼k) yeniden eÄŸitilir.
- Genellikle iki parametre grubu kullanÄ±lÄ±r: baÅŸ (classifier) iÃ§in daha bÃ¼yÃ¼k LR, omurga (backbone) iÃ§in daha kÃ¼Ã§Ã¼k LR.
- Avantaj: Hedef gÃ¶reve daha iyi uyum. Dezavantaj: AÅŸÄ±rÄ± Ã¶ÄŸrenme riski ve eÄŸitim maliyeti artar.

<a id="alexnet-transfer-data"></a>

## AlexNet â†’ CIFAR-10: Veri ve DÃ¶nÃ¼ÅŸÃ¼mler

- CIFAR-10 gÃ¶rÃ¼ntÃ¼leri 32Ã—32â€™dir; ImageNet Ã¶n-eÄŸitimli aÄŸÄ± kullanmak iÃ§in 224Ã—224â€™e yeniden boyutlandÄ±rÄ±lÄ±r ve ImageNet istatistikleri ile normalize edilir.
- Torchvisionâ€™Ä±n modern `weights` APIâ€™si, doÄŸru Ã¶n-iÅŸlemeyi otomatik saÄŸlayabilir.

Ã–rnek (eÄŸitim/validasyon dÃ¶nÃ¼ÅŸÃ¼mleri):

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torchvision.models import AlexNet_Weights

weights = AlexNet_Weights.IMAGENET1K_V1

train_tf = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=weights.meta['mean'], std=weights.meta['std']),
])

test_tf = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=weights.meta['mean'], std=weights.meta['std']),
])

trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_tf)
testset  = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_tf)

trainloader = DataLoader(trainset, batch_size=64, shuffle=True)
testloader  = DataLoader(testset,  batch_size=64, shuffle=False)
```

Not: BazÄ± Ã¶rneklerde `testloader = DataLoader(trainset, ...)` hatasÄ± gÃ¶rÃ¼lebilir; test loaderâ€™da `testset` kullanÄ±lmalÄ±dÄ±r.

<a id="alexnet-transfer-model"></a>

## AlexNet â†’ CIFAR-10: Model ve Dondurma/Ã‡Ã¶zme

Ã–zellik Ã§Ä±karma (yalnÄ±zca son katman eÄŸitilir):

```python
import torch
import torch.nn as nn
from torchvision.models import alexnet, AlexNet_Weights

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

weights = AlexNet_Weights.IMAGENET1K_V1
model = alexnet(weights=weights)

# TÃ¼m aÄŸÄ± dondur
for p in model.parameters():
    p.requires_grad = False

# SÄ±nÄ±f sayÄ±sÄ±nÄ± 10â€™a uyarla
num_ftrs = model.classifier[6].in_features
model.classifier[6] = nn.Linear(num_ftrs, 10)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.classifier[6].parameters(), lr=1e-3)
```

Ä°nce ayar (Ã¼st katmanlarÄ± Ã§Ã¶z, farklÄ± LRâ€™lar):

```python
# Ã–nce herkesi dondur
for p in model.parameters():
    p.requires_grad = False

# Ãœst katmanlarÄ± (Ã¶r. tÃ¼m classifier) Ã§Ã¶z
for p in model.classifier.parameters():
    p.requires_grad = True

# (Ä°steÄŸe baÄŸlÄ±) son konvolÃ¼syon bloÄŸunu Ã§Ã¶zmek iÃ§in ad-hoc seÃ§im yapÄ±labilir
# Ã–rn: for name, p in model.named_parameters():
#          if name.startswith('features.10'): p.requires_grad = True

# Parametre gruplarÄ±: baÅŸ iÃ§in daha bÃ¼yÃ¼k, omurga iÃ§in daha kÃ¼Ã§Ã¼k LR
head_params = filter(lambda p: p.requires_grad, model.parameters())
optimizer = torch.optim.SGD([
    { 'params': model.classifier.parameters(), 'lr': 1e-3 },
    # {'params': backbone_params, 'lr': 1e-4},  # omurga Ã§Ã¶zÃ¼lÃ¼rse ekleyin
], momentum=0.9)
```

<a id="alexnet-transfer-train-eval"></a>

## AlexNet Transfer: EÄŸitim ve DeÄŸerlendirme

Basit eÄŸitim dÃ¶ngÃ¼sÃ¼:

```python
num_epochs = 5
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in trainloader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print(f"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}")

model.eval()
correct = 0
total = 0
with torch.no_grad():
    for inputs, labels in testloader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, pred = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (pred == labels).sum().item()
print(f"Test DoÄŸruluÄŸu: {100.0*correct/total:.2f}%")
```

Ä°puÃ§larÄ± / Notlar:

- EÄŸitimde `model.train()`, deÄŸerlendirmede `model.eval()` kullanÄ±n; `torch.no_grad()` bellek tasarrufu saÄŸlar.
- Ä°nce ayarda erken durdurma, aÄŸÄ±rlÄ±k Ã§Ã¼rÃ¼mesi (weight decay) ve daha uzun epoch sayÄ±sÄ± genellikle faydalÄ±dÄ±r.
- `pretrained=True` eski APIâ€™dÄ±r; artÄ±k `weights=AlexNet_Weights.IMAGENET1K_V1` kullanÄ±n.

<a id="vgg16"></a>

## VGG-16: Mimari ve Transfer

### Ã–zet

- VGG (Visual Geometry Group), kÃ¼Ã§Ã¼k 3Ã—3 konvolÃ¼syonlarÄ± art arda kullanarak derinliÄŸin performansa katkÄ±sÄ±nÄ± gÃ¶sterdi. VGG-16/VGG-19 basit ve homojen bir mimariyle ResNet Ã¶ncesi dÃ¶nemin SOTAâ€™sÄ±nÄ± belirledi.
- VGG-16, gÃ¼nÃ¼mÃ¼zde de transfer Ã¶ÄŸrenme iÃ§in gÃ¼Ã§lÃ¼ ve sezgisel bir Ã¶zellik Ã§Ä±karÄ±cÄ±dÄ±r (ancak parametre ve hesaplama maliyeti yÃ¼ksektir; â‰ˆ138M parametre).

### HÄ±zlÄ± Notlar

- 3Ã—3 filtreler + max-pooling bloklarÄ±; sonunda bÃ¼yÃ¼k tam baÄŸlÄ± katmanlar (4096â†’4096â†’C).
- Derinlik artÄ±rma: Daha kÃ¼Ã§Ã¼k Ã§ekirdeklerle daha derin aÄŸlar ve daha fazla doÄŸrusal olmayanlÄ±k.

### Kod: Son KatmanÄ± DeÄŸiÅŸtir (CIFARâ€‘10)

```python
import torch.nn as nn
from torchvision.models import vgg16, VGG16_Weights

weights = VGG16_Weights.IMAGENET1K_V1
model = vgg16(weights=weights)
num_ftrs = model.classifier[6].in_features
model.classifier[6] = nn.Linear(num_ftrs, 10)
```

### Kod: Ã–zel SÄ±nÄ±flandÄ±rÄ±cÄ± BloÄŸu

```python
import torch.nn as nn
from torchvision.models import vgg16, VGG16_Weights

weights = VGG16_Weights.IMAGENET1K_V1
model = vgg16(weights=weights)

num_ftrs = model.classifier[6].in_features  # 25088â†’4096 iÃ§in ilk FC giriÅŸi 25088â€™dir
num_classes = 10
model.classifier = nn.Sequential(
    nn.Linear(num_ftrs, 4096), nn.ReLU(True), nn.Dropout(0.5),
    nn.Linear(4096, 4096),    nn.ReLU(True), nn.Dropout(0.5),
    nn.Linear(4096, num_classes),
)
```

Ä°puÃ§larÄ±:

- `weights.transforms()` veya `Normalize(mean=weights.meta['mean'], std=weights.meta['std'])` ile doÄŸru Ã¶n-iÅŸleme uygulayÄ±n.
- Ã–zellik Ã§Ä±karma iÃ§in tÃ¼m aÄŸÄ± dondurup yalnÄ±zca `classifier`â€™Ä± eÄŸitmek daha hÄ±zlÄ±dÄ±r; ince ayarda `classifier` (ve gerekirse son konv bloÄŸu) Ã§Ã¶zÃ¼lÃ¼r.

<a id="gradients-issues"></a>

## Derin AÄŸlarda Gradyan SorunlarÄ±

### Vanishing Gradient (Kaybolan Gradyan)

- Geri yayÄ±lÄ±mda gradyanlar derin katmanlara doÄŸru kÃ¼Ã§Ã¼lÃ¼r, erken katmanlar gÃ¼ncellenemez; Ã¶ÄŸrenme durur veya Ã§ok yavaÅŸlar.
- SÄ±k sebepler: Sigmoid/tanh doygunluÄŸu, Ã§ok derin aÄŸlar, uygunsuz baÅŸlatma.

### Exploding Gradient (Patlayan Gradyan)

- Gradyanlar aÅŸÄ±rÄ± bÃ¼yÃ¼r; gÃ¼ncellemeler kararsÄ±z, loss dalgalÄ± olur; aÄŸÄ±rlÄ±klar aÅŸÄ±rÄ± bÃ¼yÃ¼yebilir.

### Ã‡Ã¶zÃ¼m YÃ¶ntemleri

- Aktivasyon: ReLU/LeakyReLU/ELU.
- Normalizasyon: BatchNorm/LayerNorm.
- YapÄ±sal: Residual (skip) baÄŸlantÄ±lar (ResNet).
- Optimizasyon: Uygun LR, LR planlarÄ±, gradient clipping, aÄŸÄ±rlÄ±k baÅŸlatma (He/Xavier).

<a id="resnet"></a>

## ResNet: Residual BaÄŸlantÄ±lar

### Ã–zet

- 2015 (He ve ark.): Skip connection ile girdi, birkaÃ§ katman sonrasÄ± Ã§Ä±ktÄ±ya toplanÄ±r (y = F(x) + x). Gradyan akÄ±ÅŸÄ± kolaylaÅŸÄ±r; Ã§ok daha derin aÄŸlar (50/101/152) eÄŸitilebilir.

### Kod: ResNet-50 Transfer (CIFARâ€‘10)

```python
import torch.nn as nn
from torchvision.models import resnet50, ResNet50_Weights

weights = ResNet50_Weights.IMAGENET1K_V1
model = resnet50(weights=weights)
for p in model.parameters():
    p.requires_grad = False
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 10)
```

<a id="inception-googlenet"></a>

## Inception (GoogLeNet): Inception ModÃ¼lÃ¼

### Ã–zet

- 1Ã—1, 3Ã—3, 5Ã—5 konv ve poolingâ€™i paralel uygular; Ã§Ä±ktÄ±larÄ±nÄ± birleÅŸtirir. FarklÄ± Ã¶lÃ§eklerde Ã¶zellikleri aynÄ± katmanda yakalar; hesaplamayÄ± 1Ã—1 â€œbottleneckâ€ ile dÃ¼ÅŸÃ¼rÃ¼r.

### Kod: Inception v3 Transfer (CIFARâ€‘10)

```python
import torch.nn as nn
from torchvision.models import inception_v3, Inception_V3_Weights

weights = Inception_V3_Weights.IMAGENET1K_V1
model = inception_v3(weights=weights, aux_logits=False)
for p in model.parameters():
    p.requires_grad = False
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 10)
# Not: Inception v3 varsayÄ±lan giriÅŸ boyutu 299'dur; weights.transforms() kullanÄ±n.
```

<a id="mobilenet"></a>

## MobileNet: Hafif Mimariler

### Ã–zet

- Depthwise separable convolution ile parametre ve FLOP maliyetini bÃ¼yÃ¼k Ã¶lÃ§Ã¼de azaltÄ±r; mobil/gÃ¶mÃ¼lÃ¼ cihazlarda verimlidir (MobileNetV1/V2, ShuffleNet benzer amaÃ§ta).

### Kod: MobileNetV2 Transfer (CIFARâ€‘10)

```python
import torch.nn as nn
from torchvision.models import mobilenet_v2, MobileNet_V2_Weights

weights = MobileNet_V2_Weights.IMAGENET1K_V1
model = mobilenet_v2(weights=weights)
for p in model.parameters():
    p.requires_grad = False
num_ftrs = model.classifier[1].in_features
model.classifier[1] = nn.Linear(num_ftrs, 10)
```

<a id="efficientnet"></a>

## EfficientNet: BileÅŸik Ã–lÃ§eklendirme

### Ã–zet

- Compound scaling: Derinlik, geniÅŸlik ve Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ dengeli birlikte Ã¶lÃ§ekler. MBConv + SE bloklarÄ± ve Swish/SiLU aktivasyonlarÄ± kullanÄ±r; yÃ¼ksek doÄŸruluk/verim dengesi sunar.

### Kod: EfficientNetâ€‘B0 Transfer (CIFARâ€‘10)

```python
import torch.nn as nn
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

weights = EfficientNet_B0_Weights.IMAGENET1K_V1
model = efficientnet_b0(weights=weights)
for p in model.parameters():
    p.requires_grad = False
num_ftrs = model.classifier[1].in_features
model.classifier[1] = nn.Linear(num_ftrs, 10)
```

### HÄ±zlÄ± Sorular

1) VGGâ€™nin basit/homojen yapÄ±sÄ±nÄ±n iki avantajÄ± nedir, iki dezavantajÄ± nedir?
2) Vanishing gradientâ€™e karÅŸÄ± Ã¼Ã§ pratik Ã§Ã¶zÃ¼m sÃ¶yleyin.
3) ResNetâ€™in â€œy = F(x) + xâ€ fikri neden derinleÅŸmeyi kolaylaÅŸtÄ±rÄ±r?
4) Inception modÃ¼lÃ¼nde 1Ã—1 konvâ€™un rolÃ¼ nedir?
5) MobileNet ve EfficientNetâ€™in verimlilik yaklaÅŸÄ±mlarÄ± nasÄ±l farklÄ±dÄ±r?

<a id="overfitting"></a>

## AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting): TanÄ±m ve Belirtiler

### TanÄ±m

- Modelin eÄŸitim verisini ezberleyip gÃ¼rÃ¼ltÃ¼yÃ¼ de Ã¶ÄŸrenmesi; yeni (gÃ¶rmediÄŸi) veride dÃ¼ÅŸÃ¼k performans gÃ¶stermesidir. Genelleme zayÄ±ftÄ±r.
- Analojisi: SorularÄ± cevaplarÄ±yla ezberleyen Ã¶ÄŸrenci, farklÄ± soruda baÅŸarÄ±sÄ±z olur.

### NasÄ±l AnlarÄ±z?

- Ä°yi durum: EÄŸitim ve doÄŸrulama hatasÄ± birlikte dÃ¼ÅŸer.
- Overfitting: EÄŸitim hatasÄ± dÃ¼ÅŸmeye devam ederken, doÄŸrulama hatasÄ± artmaya baÅŸlar (ayrÄ±ÅŸma/boÅŸluk bÃ¼yÃ¼r).

<a id="train-val-test"></a>

## Train/Validation/Test: Neden ve NasÄ±l?

- Hedef genellemedir; modelin gÃ¶rmediÄŸi verideki baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in veri Ã¼Ã§e ayrÄ±lÄ±r:
  1) EÄŸitim (%60â€“80): Ã–ÄŸrenme iÃ§in kullanÄ±lÄ±r; aÄŸÄ±rlÄ±klar bu veriye gÃ¶re gÃ¼ncellenir.
  2) DoÄŸrulama (%10â€“20): EÄŸitim sÄ±rasÄ±nda hiperparametre seÃ§imi ve overfitting tespiti iÃ§in kullanÄ±lÄ±r (Ã¶ÄŸrenme yoktur).
  3) Test (%10â€“20): TÃ¼m ayarlardan sonra nihai, tarafsÄ±z deÄŸerlendirme iÃ§in bir kez bakÄ±lÄ±r.

<a id="validation-role"></a>

## Validation Seti: Rol ve Hiperparametre AyarÄ±

- Overfitting tespiti: EÄŸitim lossâ€™u dÃ¼ÅŸerken validasyon lossâ€™unun artmasÄ± ezberlemeye iÅŸaret eder.
- Hiperparametreler: LR, katman/nÃ¶ron sayÄ±sÄ±, dropout oranÄ± vb. Validasyon setinde karÅŸÄ±laÅŸtÄ±rÄ±lÄ±p seÃ§ilir.

<a id="validation-cifar10"></a>

## Validation Seti: CIFAR-10 Ã–rnek (random_split)

```python
import torch
from torch.utils.data import random_split, DataLoader
import torchvision
from torchvision import transforms

transform = transforms.Compose([
    transforms.Resize(256), transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])
])

full_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test_set   = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

total = len(full_train)
val_size = int(total * 0.2)
train_size = total - val_size

# Deterministik bÃ¶lme iÃ§in seed
g = torch.Generator().manual_seed(42)
train_set, val_set = random_split(full_train, [train_size, val_size], generator=g)

train_loader = DataLoader(train_set, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_set,   batch_size=32, shuffle=False)
test_loader  = DataLoader(test_set,  batch_size=32, shuffle=False)
```

Notlar:

- Augmentation yalnÄ±zca eÄŸitim setine uygulanÄ±r; validasyon/test iÃ§in deterministik dÃ¶nÃ¼ÅŸÃ¼mler (Resize/CenterCrop/Normalize) kullanÄ±lÄ±r.
- AynÄ± bÃ¶lmeyi tekrarlamak iÃ§in seed sabitlenmelidir.

<a id="overfitting-causes"></a>

## AÅŸÄ±rÄ± Ã–ÄŸrenmenin Nedenleri

1) Yetersiz/temsili olmayan veri â†’ Ã§eÅŸitlilik az, gÃ¼rÃ¼ltÃ¼ ezberlenir.
2) AÅŸÄ±rÄ± karmaÅŸÄ±k model (yÃ¼ksek kapasite) â†’ gÃ¼rÃ¼ltÃ¼ dÃ¢hil her ÅŸeyi temsil eder.
3) Ã‡ok uzun eÄŸitim (overâ€‘training) â†’ eÄŸitim seti tekrar tekrar gÃ¶rÃ¼lÃ¼r, ezber artar.

<a id="overfit-prevent-data"></a>

## AÅŸÄ±rÄ± Ã–ÄŸrenmeyi Ã–nleme: Veri OdaklÄ±

- Daha fazla veri toplamak (en etkili ama zorlu yol).
- Veri artÄ±rma (data augmentation): DÃ¶ndÃ¼rme, kÄ±rpma, flip, renk/parlaklÄ±k oynamalarÄ±.

GeniÅŸletilmiÅŸ eÄŸitim augmentasyonu Ã¶rneÄŸi (gÃ¶rselleÅŸtirme amaÃ§lÄ±):

```python
from torchvision import transforms

visualization_tf = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.5, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=30),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
])
```

<a id="overfit-prevent-model"></a>

## AÅŸÄ±rÄ± Ã–ÄŸrenmeyi Ã–nleme: Model OdaklÄ±

- Kapasiteyi dÃ¼ÅŸÃ¼rmek: Daha az katman/nÃ¶ron.
- Transfer Ã¶ÄŸrenme: BÃ¼yÃ¼k veriyle Ã¶n-eÄŸitilmiÅŸ aÄŸlarÄ±n Ã¶zelliklerini yeniden kullanmak.

<a id="regularization"></a>

## DÃ¼zenlileÅŸtirme: Dropout, L1/L2 (Weight Decay)

### Dropout

```python
import torch.nn as nn

model_with_dropout = nn.Sequential(
    nn.Linear(784, 128), nn.ReLU(), nn.Dropout(p=0.5),
    nn.Linear(128, 10),  # CrossEntropyLoss ile Softmax eklemeyin (logits beklenir)
)
```

Not: CrossEntropyLoss kullanÄ±yorsanÄ±z Ã§Ä±kÄ±ÅŸta Softmax uygulamayÄ±n; NLLLoss kullanÄ±yorsanÄ±z LogSoftmax gerekir.

### L2 (Weight Decay)

```python
import torch.optim as optim

optimizer = optim.Adam(model_with_dropout.parameters(), lr=1e-3, weight_decay=1e-2)
```

### L1 (Elle ekleme)

```python
l1_lambda = 5e-3
base_loss = criterion(outputs, targets)
l1_norm = sum(p.abs().sum() for p in model.parameters())
loss = base_loss + l1_lambda * l1_norm
```

<a id="earlystop-bn"></a>

## Erken Durdurma ve Batch Normalization

### Erken Durdurma (patience=5 Ã¶rneÄŸi)

```python
best_val = float('inf')
patience, wait = 5, 0
best_state = None
for epoch in range(100):
    train_one_epoch(...)
    val_loss = evaluate_val(...)
    if val_loss < best_val - 1e-4:
        best_val, wait = val_loss, 0
        best_state = {k: v.cpu() for k, v in model.state_dict().items()}
    else:
        wait += 1
        if wait >= patience:
            break
# En iyi aÄŸÄ±rlÄ±klarÄ± yÃ¼kle
model.load_state_dict(best_state)
```

### Batch Normalization

- Conv iÃ§in `nn.BatchNorm2d(C)`, Linear iÃ§in `nn.BatchNorm1d(D)`.
- EÄŸitimde `model.train()` modunda miniâ€‘batch istatistikleri; deÄŸerlendirmede `model.eval()` modunda running istatistikler kullanÄ±lÄ±r.

<a id="assignment-transfer"></a>

## Uygulama: Transfer Ã–ÄŸrenme KÄ±yaslama GÃ¶revi

GÃ¶rev: Verilen Ã§iÃ§ekler (veya yÃ¼z/yaÅŸ) veri setinde en az Ã¼Ã§ SOTA modelle transfer Ã¶ÄŸrenme yapÄ±p karÅŸÄ±laÅŸtÄ±rÄ±n.

KoÅŸullar (Ã¶zet):

1) Modeller: MobileNetV3, InceptionV3, EfficientNetâ€‘B0.
2) EÄŸitim/test fonksiyonlarÄ±nÄ± yeniden kullanÄ±labilir yazÄ±n (model baÄŸÄ±msÄ±z).
3) BÃ¶lme: %80 eÄŸitim / %10 doÄŸrulama / %10 test; sabit random_seed ile tekrarlanabilir bÃ¶lme.
4) Hiperparametreler: batch_size=32, lr=0.001.
5) Veri artÄ±rÄ±mÄ±: EÄŸitimde uygulayÄ±n; val/test deterministik dÃ¶nÃ¼ÅŸÃ¼mler.
6) Erken durdurma: 5 adÄ±mda validasyon kaybÄ± iyileÅŸmezse durdurun.
7) KayÄ±t: Her model iÃ§in ayrÄ± klasÃ¶rde loss/acc eÄŸrileri, karÄ±ÅŸÄ±klÄ±k matrisi, metrikler ve loglar.
8) En iyi modelin aÄŸÄ±rlÄ±klarÄ±nÄ± kaydedin.
9) Her model iÃ§in yeni bir classifier baÅŸÄ± tasarlayÄ±n (Linear + Dropout [+ BatchNorm1d opsiyonel]).
10) SonuÃ§larÄ± rapor edin ve en iyi modeli belirtin.

## HiyerarÅŸik Temsil Ã–ÄŸrenimi

### Ã–zet

- Derin aÄŸlar, girdilerden katmanlar boyunca giderek daha soyut ve ayrÄ±ÅŸtÄ±rÄ±cÄ± temsiller Ã¶ÄŸrenir: pikseller â†’ kenarlar/dokular â†’ ÅŸekiller/desenler â†’ nesneler/konseptler.

### Katmanlara GÃ¶re Ã–rnekler

- Alt katmanlar: Kenarlar, dokular, basit renk/geometrik motifler.
- Orta katmanlar: Basit ÅŸekiller ve birleÅŸik desenler.
- Ãœst katmanlar: Nesne parÃ§alarÄ± ve yÃ¼ksek dÃ¼zey semantik Ã¶zellikler (Ã¶r. yÃ¼z parÃ§alarÄ±).

### HÄ±zlÄ± Sorular

1) Neden â€œÃ¶zellik mÃ¼hendisliÄŸiâ€ yerine â€œtemsili Ã¶ÄŸrenimâ€ daha avantajlÄ± olabilir?
2) PaylaÅŸÄ±mlÄ± aÄŸÄ±rlÄ±klar ve yerel alÄ±cÄ± alanlar, hiyerarÅŸik temsile nasÄ±l katkÄ± saÄŸlar?

<a id="dl-problemleri"></a>

## Derin Ã–ÄŸrenmede Zorluklar: Non-konveksite ve RastsallÄ±k

### Ã–zet

- Derinlik â‰¥ 3 olduÄŸunda kayÄ±p fonksiyonlarÄ± genellikle dÄ±ÅŸbÃ¼key deÄŸildir; teorik garantiler zayÄ±flar ve eÄŸitim sÃ¼reci baÅŸlangÄ±Ã§lara/hyperparametrelere duyarlÄ± hale gelir.

### Temel Noktalar

- Non-konveks optimizasyon: Ã‡oklu yerel minimumlar/eylemsiz bÃ¶lgeler; farklÄ± baÅŸlangÄ±Ã§lar farklÄ± Ã§Ã¶zÃ¼mlere gÃ¶tÃ¼rebilir.
- RastsallÄ±k: Stokastik sÃ¼reÃ§ler (mini-batch sÄ±rasÄ±, dropout maskeleri vb.) sonuÃ§larda deÄŸiÅŸkenliÄŸe neden olur.

### HÄ±zlÄ± Sorular

1) Non-konveks optimizasyonda pratikte hangi stratejiler kullanÄ±lÄ±r? (ipucu: iyi baÅŸlatma, Ã¶ÄŸrenme oranÄ± planlarÄ±, momentum/Adam, normalizasyon)
2) Neden aynÄ± model farklÄ± tohumlarla farklÄ± sonuÃ§lar verir?

<a id="pipeline-vs-e2e"></a>

## Boru HatlarÄ± vs UÃ§tan Uca Sistemler

### Ã–zet

- Pipeline sistemlerde her adÄ±m ayrÄ± deÄŸerlendirilir ve hata kaynaÄŸÄ± kolay izole edilir; uÃ§tan uca sistemlerde performans yÃ¼ksek olabilir fakat neden/niÃ§in Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± teÅŸhis zorlaÅŸÄ±r.

### Notlar

- Pipeline: Ã–zellik Ã§Ä±karma â†’ modelleme â†’ karar; adÄ±m baÅŸÄ±na metriklerle teÅŸhis.
- UÃ§tan uca: Ham girdiden Ã§Ä±ktÄ±ya tek model; hata analizinde aÃ§Ä±klanabilirlik ek araÃ§lar gerektirir.

### HÄ±zlÄ± Sorular

1) Hangi senaryolarda pipeline tercih edilir, hangilerinde uÃ§tan uca?
2) UÃ§tan uca sistemlerde yorumlanabilirliÄŸi artÄ±rmak iÃ§in iki yÃ¶ntem sÃ¶yleyin.

<a id="ann-intro"></a>

## Yapay Sinir AÄŸlarÄ±: TanÄ±m ve BileÅŸenler

### Ã–zet

- Yapay Sinir AÄŸlarÄ± (YSA), biyolojik sinir sistemlerinden esinlenen ve zekÃ¢/Ã¶ÄŸrenme yetilerini taklit etmeyi amaÃ§layan hesaplama modelleridir. Temelinde sinir hÃ¼crelerinin (nÃ¶ron) matematiksel olarak modellenmesi yatar.

### Temel Kavramlar

- NÃ¶ron: AÄŸÄ±rlÄ±klÄ± giriÅŸlerin toplandÄ±ÄŸÄ± ve bir aktivasyon fonksiyonundan geÃ§irildiÄŸi temel hesaplama birimi.
- Katmanlar: Girdi katmanÄ± â†’ gizli katman(lar) â†’ Ã§Ä±ktÄ± katmanÄ±; derinlik arttÄ±kÃ§a temsil gÃ¼cÃ¼ artar.
- BaÄŸlantÄ±lar ve AÄŸÄ±rlÄ±klar: Ã–ÄŸrenmenin gerÃ§ekleÅŸtiÄŸi parametreler; gradyan temelli yÃ¶ntemlerle gÃ¼ncellenir.

### Notlar

- GÃ¶rseller (#13.jpg, #14.jpg) metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.

### HÄ±zlÄ± Sorular

1) Bir YSAâ€™nÄ±n Ã¼Ã§ temel bileÅŸeni nedir?
2) Derinlik neden temsil gÃ¼cÃ¼nÃ¼ artÄ±rÄ±r?

<a id="neuron-activation"></a>

## NÃ¶ron Aktivasyonu ve Hesaplama

### Ã–zet

- Bir nÃ¶ron, giriÅŸ vektÃ¶rÃ¼nÃ¼ aÄŸÄ±rlÄ±klarla Ã§arpar, bias ekler ve sonucu bir aktivasyon fonksiyonundan geÃ§irir: $a = w^\top x + b$, $y = h(a)$.

### Detaylar

- AÄŸÄ±rlÄ±klÄ± Toplam: $a = \sum_i w_i x_i + b$.
- Aktivasyon: $y = h(a)$; $h(\cdot)$ genellikle doÄŸrusal olmayan bir fonksiyondur.
- Kesinlikle Artan Fonksiyon: $x_1 < x_2$ ise $g(x_1) < g(x_2)$ (kararÄ± korur; tÃ¼revi negatif deÄŸildir).

### HÄ±zlÄ± Sorular

1) Neden doÄŸrusal olmayan aktivasyonlara ihtiyaÃ§ duyarÄ±z?
2) AÄŸÄ±rlÄ±klÄ± toplamÄ±n Ã¶nÃ¼ne normalizasyon eklemek neyi iyileÅŸtirir?

<a id="activation-functions"></a>

## Aktivasyon FonksiyonlarÄ±: Lineer, Sigmoid, Tanh, ReLU

### Ã–zet

- Aktivasyon seÃ§imi optimizasyonu, temsil gÃ¼cÃ¼nÃ¼ ve genelleme kapasitesini etkiler. YaygÄ±n seÃ§enekler: lineer, sigmoid, tanh, ReLU.

### TanÄ±mlar ve Ã–zellikler

- Lineer: $f(x) = x$. Derin aÄŸlarda yalnÄ±zca lineer kullanÄ±lÄ±rsa tÃ¼m aÄŸ yine lineer olur (temsil gÃ¼cÃ¼ sÄ±nÄ±rlÄ±).
- Sigmoid: $\sigma(x) = \frac{1}{1 + e^{-x}}$. AralÄ±k $(0,1)$; doygunluk bÃ¶lgelerinde gradyan sÃ¶nÃ¼mlenir; sÄ±fÄ±r merkezli deÄŸildir.
- Tanh: $\tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$. AralÄ±k $(-1,1)$; sÄ±fÄ±r merkezli; yine doygunluklarda gradyan zayÄ±flar.
- ReLU: $\mathrm{ReLU}(x) = \max(0,x)$. Hesaplama olarak ucuz; seyreklik Ã¼retir; Ã¼st sÄ±nÄ±r yok; â€œÃ¶lÃ¼ ReLUâ€ riski (gradyan 0â€™a kilitlenebilir).

### Ä°puÃ§larÄ±

- Derin aÄŸlarda ReLU-tÃ¼revleri pratikte daha hÄ±zlÄ± ve stabildir; sigmoid/tanh genelde sÄ±nÄ±rlÄ± katmanlarda tercih edilir veya dikkatli baÅŸlatma/normalizasyonla kullanÄ±lÄ±r.

### HÄ±zlÄ± Sorular

1) Sigmoid ve tanhâ€™Ä±n ortak dezavantajÄ± nedir?
2) ReLUâ€™nun iki pratik avantajÄ±nÄ± sayÄ±n.

<a id="relu-sparsity"></a>

## ReLU ve Seyrek Aktivite

### Ã–zet

- ReLU, negatif girdilerde sÄ±fÄ±r Ã§Ä±ktÄ±sÄ± Ã¼reterek birÃ§ok nÃ¶ronu pasif bÄ±rakÄ±r; bu â€œseyrek aktiviteâ€ hem hesaplamayÄ± hÄ±zlandÄ±rÄ±r hem de daha ayÄ±rt edici temsillere katkÄ±da bulunur.

### Mekanizma

- TanÄ±m: $f(x) = \max(0, x)$.
- Ä°leri YayÄ±lÄ±m: $x < 0$ iken Ã§Ä±ktÄ± $0$; bir sonraki katmana bilgi taÅŸÄ±nmaz.
- Geri YayÄ±lÄ±m: Pasif nÃ¶ron gradyan almaz; etkili parametre sayÄ±sÄ± azalÄ±r (dÃ¼zenlileÅŸtirici etki).

### Neden Ã–nemli?

- HÄ±z: SÄ±fÄ±r Ã§Ä±ktÄ±lar sonraki katmanlarda hesaplama yÃ¼kÃ¼nÃ¼ dÃ¼ÅŸÃ¼rÃ¼r.
- Temsil: Biyolojik sistemlerde de gÃ¶zlenen seyreklik, daha bilgi-zengin ve ayrÄ±ÅŸtÄ±rÄ±cÄ± temsil ile iliÅŸkilidir.

### HÄ±zlÄ± Sorular

1) ReLUâ€™nun â€œseyrek aktiviteâ€ Ã¼retmesi neden hesaplamayÄ± hÄ±zlandÄ±rÄ±r?
2) ReLUâ€™da â€œÃ¶lÃ¼ nÃ¶ronâ€ problemi nedir ve nasÄ±l azaltÄ±labilir? (ipucu: He init, Leaky ReLU, uygun LR)

<a id="perceptron-forward"></a>

## Perceptron: Ä°leri YayÄ±lÄ±m

### Ã–zet

- Perceptron tek katmanlÄ± bir doÄŸrusal sÄ±nÄ±flandÄ±rÄ±cÄ±dÄ±r; giriÅŸlerin aÄŸÄ±rlÄ±klÄ± toplamÄ±nÄ± alÄ±r ve bir aktivasyon fonksiyonundan geÃ§irir.

### FormÃ¼l (Tek Ã‡Ä±kÄ±ÅŸ)

- GiriÅŸ $x \in \mathbb{R}^d$, aÄŸÄ±rlÄ±k $w \in \mathbb{R}^d$, bias $b \in \mathbb{R}$.
- Ã–n-aktivasyon: $a = w^\top x + b$.
- Ã‡Ä±kÄ±ÅŸ: $\hat{y} = h(a)$.

### FormÃ¼l (Ã‡oklu Ã‡Ä±kÄ±ÅŸ / C sÄ±nÄ±f)

- AÄŸÄ±rlÄ±k matrisi $W \in \mathbb{R}^{C \times d}$, bias $b \in \mathbb{R}^C$.
- Logitler: $a = W x + b$.
- SÄ±nÄ±flandÄ±rmada tipik olarak $h$ olarak softmax kullanÄ±lÄ±r: $\hat{y} = \mathrm{softmax}(a)$.

### HÄ±zlÄ± Sorular

1) Perceptronâ€™da aktivasyon fonksiyonu doÄŸrusal olursa ne olur?
2) Ã‡oklu Ã§Ä±kÄ±ÅŸ durumunda neden vektÃ¶r bias gerekir?

<a id="softmax"></a>

## Softmax Aktivasyonu ve Ã–zellikleri

### Ã–zet

- Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rmada her sÄ±nÄ±f iÃ§in koÅŸullu olasÄ±lÄ±k $P(c\mid x)$ tahmini Ã¼retir. Ã‡Ä±kÄ±ÅŸ bileÅŸenleri pozitiftir ve toplamlarÄ± $1$â€™dir.

### TanÄ±m

$$\mathrm{softmax}(a)_i = \frac{\exp(a_i)}{\sum_{c=1}^{C} \exp(a_c)} \quad \text{veya} \quad \mathbf{o}(\mathbf{a}) = \left[\frac{\exp(a_1)}{\sum_c \exp(a_c)},\dots,\frac{\exp(a_C)}{\sum_c \exp(a_c)}\right]^\top$$

### Ã–zellikler

- Pozitiflik: $\mathrm{softmax}(a)_i > 0$.
- Toplam Bir: $\sum_i \mathrm{softmax}(a)_i = 1$.
- Tahmin: $\arg\max_i \, \mathrm{softmax}(a)_i$ en olasÄ± sÄ±nÄ±f.

### Ä°puÃ§larÄ±

- SayÄ±sal KararlÄ±lÄ±k: $\mathrm{softmax}(a) = \mathrm{softmax}(a - \max(a))$ (log-sum-exp hilesi) ile taÅŸmalarÄ± Ã¶nleyin.
- SÄ±caklÄ±k (opsiyonel): $\mathrm{softmax}(a/T)$; $T>1$ daha dÃ¼z, $T<1$ daha keskin daÄŸÄ±lÄ±m verir.

### HÄ±zlÄ± Sorular

1) Neden softmaxâ€™e girmeden Ã¶nce logitlerden $\max(a)$ Ã§Ä±karÄ±lÄ±r?
2) $T$ sÄ±caklÄ±ÄŸÄ± artÄ±rÄ±ldÄ±ÄŸÄ±nda daÄŸÄ±lÄ±m nasÄ±l deÄŸiÅŸir?

<a id="one-hidden-layer"></a>

## Tek Gizli KatmanlÄ± Sinir AÄŸÄ±

### Ã–zet

- GiriÅŸten gizli katmana doÄŸrusal dÃ¶nÃ¼ÅŸÃ¼m + doÄŸrusal olmayan aktivasyon, ardÄ±ndan Ã§Ä±ktÄ± katmanÄ±na doÄŸrusal dÃ¶nÃ¼ÅŸÃ¼m ve sÄ±nÄ±flandÄ±rmada softmax.

### FormÃ¼l ve Boyutlar

- GiriÅŸ $x \in \mathbb{R}^d$.
- Gizli katman: $z = W_1 x + b_1$, $h = \phi(z)$, burada $W_1 \in \mathbb{R}^{m \times d}$, $b_1 \in \mathbb{R}^m$.
- Ã‡Ä±kÄ±ÅŸ (logit): $a = W_2 h + b_2$, burada $W_2 \in \mathbb{R}^{C \times m}$, $b_2 \in \mathbb{R}^C$.
- SÄ±nÄ±flandÄ±rma: $\hat{y} = \mathrm{softmax}(a)$.

### Notlar

- Gizli aktivasyon $\phi$ olarak ReLU/tanh/sigmoid seÃ§ilebilir; pratikte Ã§oÄŸunlukla ReLU-tÃ¼revleri kullanÄ±lÄ±r.
- GÃ¶rseller (#21â€“#27) metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lerek Ã¶zetlenmiÅŸtir.

### HÄ±zlÄ± Sorular

1) Neden iki doÄŸrusal katmanÄ± arka arkaya koymak tek doÄŸrusal dÃ¶nÃ¼ÅŸÃ¼me eÅŸdeÄŸerdir?
2) Gizli katman boyutu $m$ arttÄ±kÃ§a hangi riskler ortaya Ã§Ä±kar?

<a id="mlp-general"></a>

## Ã‡ok KatmanlÄ± Perceptron (Genel Ä°leri YayÄ±lÄ±m)

### Ã–zet

- L adet gizli katmana sahip MLPâ€™de her katmanda doÄŸrusal dÃ¶nÃ¼ÅŸÃ¼m ve doÄŸrusal olmayan aktivasyon uygulanÄ±r; Ã§Ä±ktÄ± katmanÄ± gÃ¶rev tipine gÃ¶re belirlenir (sÄ±nÄ±flandÄ±rma/regresyon).

### Ä°leri YayÄ±lÄ±m Denklemleri

- Girdi: $h^{(0)} = x \in \mathbb{R}^{n_0}$.
- Katman $k = 1,\dots,L$ iÃ§in Ã¶n-aktivasyon ve aktivasyon:
    - $a^{(k)} = W^{(k)} h^{(k-1)} + b^{(k)}$, burada $W^{(k)} \in \mathbb{R}^{n_k \times n_{k-1}}$, $b^{(k)} \in \mathbb{R}^{n_k}$.
    - $h^{(k)} = \phi^{(k)}\!\big(a^{(k)}\big)$.
- Ã‡Ä±kÄ±ÅŸ katmanÄ± ($k=L+1$):
    - $a^{(L+1)} = W^{(L+1)} h^{(L)} + b^{(L+1)}$.
    - SÄ±nÄ±flandÄ±rma: $\hat{y} = \mathrm{softmax}\big(a^{(L+1)}\big)$ (Ã§ok sÄ±nÄ±flÄ±) veya $\hat{y}=\sigma\big(a^{(L+1)}\big)$ (ikili).
    - Regresyon: $\hat{y} = a^{(L+1)}$ (lineer Ã§Ä±ktÄ±).

### Toplam Parametre ve Hesaplama

- Parametre SayÄ±sÄ±: $\sum_{k=1}^{L+1} (n_k n_{k-1} + n_k)$.
- Ä°leri geÃ§iÅŸ karmaÅŸÄ±klÄ±ÄŸÄ± yaklaÅŸÄ±k $\mathcal{O}\!\left(\sum_k n_k n_{k-1}\right)$ Ã§arpÄ±m-toplama iÅŸlemleri.

### HÄ±zlÄ± Sorular

1) AynÄ± aktivasyon tÃ¼m katmanlarda ÅŸart mÄ±dÄ±r? Neden?
2) Ã‡Ä±kÄ±ÅŸ katmanÄ±nÄ±n aktivasyonu gÃ¶reve gÃ¶re neden deÄŸiÅŸir?

<a id="deep-nn"></a>

## Derin Sinir AÄŸÄ±

### Ã–zet

- Gizli katman sayÄ±sÄ± arttÄ±kÃ§a (derinlik), modelin temsil gÃ¼cÃ¼ ve hiyerarÅŸik Ã¶zellik Ã¶ÄŸrenimi artar; aynÄ± zamanda optimizasyon ve genelleme zorluklarÄ± da artar.

### Notlar

- Derinlik â‰¥ 3 genellikle â€œderinâ€ olarak adlandÄ±rÄ±lÄ±r; pratikte residual/skip baÄŸlantÄ±larÄ± daha derin aÄŸlarÄ±n eÄŸitimini kolaylaÅŸtÄ±rÄ±r.

### HÄ±zlÄ± Sorular

1) DerinleÅŸirken hangi dÃ¼zenlileÅŸtirme teknikleri faydalÄ±dÄ±r? (Ã¶r. dropout, weight decay, batch norm)

<a id="flight-delay"></a>

## Ã–rnek: UÃ§uÅŸum Gecikecek mi?

### Problem TanÄ±mÄ±

- Girdi Ã¶zellikleri Ã¶rneÄŸi: SÄ±caklÄ±k (Â°F), RÃ¼zgÃ¢r HÄ±zÄ± (mph), gÃ¼n/saat, hava durumu vb.
- AmaÃ§: Gecikme var/yok (ikili sÄ±nÄ±flandÄ±rma) veya gecikme sÃ¼resi (regresyon) tahmini.

### Basit MLP Kurulumu (Ä°kili SÄ±nÄ±flandÄ±rma)

- Girdi $x \in \mathbb{R}^{d}$ (normalize/standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ).
- Gizli: $h=\phi(W_1 x + b_1)$.
- Ã‡Ä±kÄ±ÅŸ: $p=\sigma(W_2 h + b_2)$; $p = P(\text{gecikme}\mid x)$.

### Notlar

- Ã–zellik Ã¶lÃ§ekleme performansÄ± ciddi etkiler; kategorik deÄŸiÅŸkenler iÃ§in one-hot/embedding kullanÄ±labilir.

### HÄ±zlÄ± Sorular

1) Bu problemde neden softmax yerine sigmoid uygundur?
2) Hangi durumlarda bunu Ã§ok sÄ±nÄ±flÄ± bir probleme Ã§evirebiliriz?

<a id="losses"></a>

## KayÄ±p FonksiyonlarÄ± ve Toplam KayÄ±p

### Ã‡apraz Entropi (Softmax â€“ Ã‡ok SÄ±nÄ±flÄ±)

$$\ell_{CE}(\hat{y}, y) = - \sum_{c=1}^{C} y_c \, \log \hat{y}_c, \quad \hat{y} = \mathrm{softmax}(a)$$

### Ä°kili Ã‡apraz Entropi (Sigmoid â€“ Ä°kili)

$$\ell_{BCE}(p, y) = - \big[ y\,\log p + (1-y)\,\log(1-p) \big], \quad p = \sigma(a)$$

### Ortalama Kare Hata (Regresyon)

$$\ell_{MSE}(\hat{y}, y) = \tfrac{1}{2} \, \lVert \hat{y} - y \rVert^2$$

### Veri Ãœzerinde Toplam KayÄ±p ve DÃ¼zenlileÅŸtirme

$$J(\theta) = \frac{1}{N} \sum_{i=1}^{N} \ell\big(\hat{y}^{(i)}, y^{(i)}\big) + \lambda\,\Omega(\theta)$$

Burada $\Omega(\theta)$ genellikle $\tfrac{1}{2}\lVert \theta \rVert_2^2$ (L2) veya $\lVert \theta \rVert_1$ (L1) olarak seÃ§ilir.

### Notlar

- Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rmada softmax + Ã§apraz entropi; ikili durumda sigmoid + ikili Ã§apraz entropi tercih edilir. MSE Ã§oÄŸunlukla regresyon iÃ§in uygundur.

### HÄ±zlÄ± Sorular

1) Neden Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rmada MSE yerine Ã§apraz entropi tercih edilir?
2) L2 aÄŸÄ±rlÄ±k cezalandÄ±rmasÄ± (weight decay) ne iÅŸe yarar?

<a id="training"></a>

## EÄŸitim SÃ¼reci ve Optimizasyon

### Ã–zet

- EÄŸitim, hatayÄ± azaltacak ÅŸekilde aÄŸÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ±n (parametrelerinin) gÃ¼ncellendiÄŸi yinelemeli bir sÃ¼reÃ§tir. Bir epoch, tÃ¼m eÄŸitim verisinin modelden bir kez geÃ§irilmesidir.

### AdÄ±m AdÄ±m (Epoch iÃ§inde)

1) BaÅŸlatma: AÄŸÄ±rlÄ±klarÄ± rastgele baÅŸlat (uygun daÄŸÄ±lÄ±m: He/Xavier). BiaslarÄ± kÃ¼Ã§Ã¼k deÄŸerlerle baÅŸlat.
2) Ä°leri YayÄ±lÄ±m: Her mini-batch iÃ§in $\hat{y}=f_\theta(x)$ hesapla.
3) KayÄ±p: SeÃ§ilen kayÄ±p fonksiyonuyla $\ell(\hat{y}, y)$ hesapla.
4) Geri YayÄ±lÄ±m: Zincir kuralÄ±yla $\nabla_\theta J(\theta)$ gradyanlarÄ±nÄ± bul.
5) GÃ¼ncelleme: Bir optimizer ile parametreleri gÃ¼ncelle: $\theta \leftarrow \theta - \eta\,\nabla_\theta J(\theta)$.
6) Tekrar: Erken durdurma/Ã¶ÄŸrenme oranÄ± planÄ±na gÃ¶re epochâ€™lar boyunca devam et.

### Terimler

- Epoch: TÃ¼m eÄŸitim veri seti Ã¼zerinde bir tam geÃ§iÅŸ.
- Mini-batch: Verinin kÃ¼Ã§Ã¼k bir altkÃ¼mesi; her gÃ¼ncellemede kullanÄ±lÄ±r.
- Ä°terasyon: Bir mini-batchâ€™in iÅŸlenmesi ve tek bir gÃ¼ncelleme adÄ±mÄ±.

### Optimizerâ€™lar ve Ã–ÄŸrenme OranÄ±

- SGD: $\theta \leftarrow \theta - \eta\,g$.
- Momentum: Birikimli yÃ¶n ile hÄ±zlandÄ±rÄ±r.
- Adam: UyarlanÄ±r Ã¶ÄŸrenme oranÄ± + moment tahmini; pratikte sÄ±klÄ±kla etkilidir.
- Ã–ÄŸrenme OranÄ± (LR): Ã‡ok bÃ¼yÃ¼kse sapma/kararsÄ±zlÄ±k, Ã§ok kÃ¼Ã§Ã¼kse yavaÅŸ yakÄ±nsama; planlar: step/plateau, cosine, warmup.

### HÄ±zlÄ± Sorular

1) Neden mini-batch kullanÄ±rÄ±z, tam-batch yerine?
2) LR Ã§ok bÃ¼yÃ¼k/Ã§ok kÃ¼Ã§Ã¼k olduÄŸunda ne gÃ¶zlemlersiniz?
3) Hangi durumlarda Adam yerine saf SGD (+momentum) tercih edilir?

<a id="tf-playground"></a>

## Ä°nteraktif: TensorFlow Playground

- Basit MLP yapÄ±landÄ±rmalarÄ±nÄ± etkileÅŸimli olarak deneyin: https://playground.tensorflow.org/
- Not: Ã–zellik Ã¶lÃ§ekleme, aktivasyon ve karar sÄ±nÄ±rlarÄ±nÄ±n nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶zlemleyin; aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi gÃ¶rmek iÃ§in veri gÃ¼rÃ¼ltÃ¼sÃ¼ ve model kapasitesiyle oynayÄ±n.

<a id="iris-problem"></a>

## Iris: Problem TanÄ±mÄ±

### Ã–zet

- Iris veri seti 150 Ã¶rnek ve 3 sÄ±nÄ±ftan (Setosa, Versicolor, Virginica) oluÅŸur. Ã–zellikler: sepal uzunluÄŸu/geniÅŸliÄŸi, petal uzunluÄŸu/geniÅŸliÄŸi (4 boyut). AmaÃ§: Ã¶rneÄŸi doÄŸru classâ€™a atamak (Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma).

### Notlar

- Dengeli ve kÃ¼Ã§Ã¼k bir veri setidir; hÄ±zlÄ± prototipleme iÃ§in uygundur.

<a id="iris-load-split"></a>

## Iris: Veriyi YÃ¼kleme ve BÃ¶lme

### AdÄ±mlar

- sklearn.datasets.load_iris ile veriyi yÃ¼kleyin; $X \in \mathbb{R}^{N\times 4}$, $y \in \{0,1,2\}$.
- train_test_split ile eÄŸitim/test ayÄ±rÄ±mÄ± (Ã¶r. test_size=0.2, random_state=42).
- PyTorch tensÃ¶r tipleri: Ã¶zellikler `float32`, etiketler `long` (CrossEntropyLoss iÃ§in gereklidir).

### Ä°puÃ§larÄ±

- Ã–zellikleri standardize etmek (Ã¶r. StandardScaler) genellikle eÄŸitimi hÄ±zlandÄ±rÄ±r ve kararlÄ±lÄ±ÄŸÄ± artÄ±rÄ±r.

<a id="iris-dataset"></a>

## Iris: Dataset ve DataLoader

### Ã–zet

- `torch.utils.data.Dataset` ile Ã¶zel bir sÄ±nÄ±f yazÄ±p `__len__` ve `__getitem__` metodlarÄ±nÄ± tanÄ±mlayÄ±n. `DataLoader` ile mini-batch (Ã¶r. 16) ve `shuffle=True` (eÄŸitim) kullanÄ±n.

### Notlar

- Test `DataLoader`â€™Ä±nda `shuffle=False` uygundur. BÃ¼yÃ¼k verilerde num_workers>0 ile hÄ±zlanma saÄŸlanabilir.

<a id="iris-model"></a>

## Iris: Model (SimpleClassifier)

### Mimari

- `fc1: 4 â†’ 10`, `fc2: 10 â†’ 10`, `fc3: 10 â†’ 3`; ara katmanlarda ReLU, Ã§Ä±kÄ±ÅŸta aktivasyon yok (logit). KayÄ±p fonksiyonu softmax ile birlikte CrossEntropyLoss olduÄŸundan, logit beklenir.

### Ã–nemli Nokta

- `nn.CrossEntropyLoss` giriÅŸ olarak `logits` (ÅŸekil `[N, C]`) ve hedef olarak `long` sÄ±nÄ±f indeksleri (ÅŸekil `[N]`) bekler. Ã‡Ä±kÄ±ÅŸ katmanÄ±na softmax eklemeyin.

<a id="iris-train"></a>

## Iris: EÄŸitim DÃ¶ngÃ¼sÃ¼

### Kurulum

- Ã–ÄŸrenme oranÄ±: 0.01, epoch: 100 (Ã¶rnek). Optimizer: Adam. KayÄ±p: CrossEntropyLoss.

### DÃ¶ngÃ¼

- Her batch iÃ§in: ileri yayÄ±lÄ±m â†’ kayÄ±p â†’ optimizer.zero_grad() â†’ loss.backward() â†’ optimizer.step(). Her 10 epochâ€™ta bir kaybÄ± yazdÄ±rÄ±n.

### Ä°puÃ§larÄ±

- `model.train()` eÄŸitimde, `model.eval()` deÄŸerlendirmede. Erken durdurma/Ã¶ÄŸrenme oranÄ± planlarÄ± eklenebilir.

<a id="iris-eval"></a>

## Iris: DeÄŸerlendirme ve DoÄŸruluk

### AdÄ±mlar

- `model.eval()` ve `torch.no_grad()` bloklarÄ± ile ileri yayÄ±lÄ±m; `_, predicted = torch.max(outputs, 1)` ile sÄ±nÄ±f indeksini alÄ±n. DoÄŸruluk: doÄŸru/total.

### Notlar

- KarÄ±ÅŸÄ±klÄ±k matrisi, sÄ±nÄ±f baÅŸÄ±na doÄŸruluk gibi ek metrikler daha zengin analiz saÄŸlar.

<a id="iris-save-load"></a>

## Iris: Model Kaydetme / YÃ¼kleme

### KayÄ±t

- YalnÄ±zca aÄŸÄ±rlÄ±klarÄ± kaydetmek yaygÄ±ndÄ±r: `torch.save(model.state_dict(), "model.pth")`.

### YÃ¼kleme

- AynÄ± mimariyi baÅŸlatÄ±n ve aÄŸÄ±rlÄ±klarÄ± yÃ¼kleyin:
- `model = SimpleClassifier(input_size=4, num_classes=3)`
- `state = torch.load("model.pth")  # gerekirse map_location` 
- `model.load_state_dict(state)`
- `model.eval()`

### Dikkat

- Kodunuzdaki `NeuralNetwork()` yerine `SimpleClassifier(...)` kullanÄ±n; mimari uyuÅŸmazlÄ±ÄŸÄ± hata verir.
- BazÄ± PyTorch sÃ¼rÃ¼mlerinde `torch.load(..., weights_only=True)` parametresi mevcut deÄŸildir; uyum iÃ§in yalnÄ±zca `torch.load(path)` kullanÄ±n.

<a id="binary-problem"></a>

## Ä°kili SÄ±nÄ±flandÄ±rma: Problem ve DÃ¶nÃ¼ÅŸÃ¼m

### Ã–zet

- Breast Cancer veri seti iki sÄ±nÄ±flÄ±dÄ±r. Ã‡ok sÄ±nÄ±flÄ± bir kurulumdan ikili sÄ±nÄ±flandÄ±rmaya geÃ§erken, Ã§Ä±ktÄ± katmanÄ± boyutu 1â€™e iner ve aktivasyon/kiÅŸi kaybÄ± ikili forma dÃ¶ner.

### DÃ¶nÃ¼ÅŸÃ¼m Ä°lkeleri

- Ã‡Ä±ktÄ±: $\hat{p} = \sigma(a)$ tek bir olasÄ±lÄ±k (pozitif sÄ±nÄ±f olasÄ±lÄ±ÄŸÄ±).
- KayÄ±p: Binary Cross-Entropy (BCE) veya sayÄ±sal olarak kararlÄ± `BCEWithLogitsLoss` (Ã§Ä±kÄ±ÅŸta sigmoid gerekmez).
- Etiket tipi: `float` (0.0/1.0) veya `long` da olabilir, fakat BCE iÃ§in `float` kullanÄ±mÄ± yaygÄ±ndÄ±r.

### HÄ±zlÄ± Sorular

1) Ã‡ok sÄ±nÄ±flÄ±dan ikiliye geÃ§erken hangi iki bileÅŸeni deÄŸiÅŸtirirsiniz?
2) Neden `BCEWithLogitsLoss`, `BCELoss` + `sigmoid` ikilisine gÃ¶re daha kararlÄ±dÄ±r?

<a id="bc-load-split"></a>

## Breast Cancer: Veriyi YÃ¼kleme ve BÃ¶lme

### AdÄ±mlar

- `load_breast_cancer()` ile veriyi yÃ¼kleyin; $X \in \mathbb{R}^{N\times d}$, $y \in \{0,1\}$.
- `train_test_split(X, y, test_size=0.2, random_state=42)` ile ayÄ±rÄ±n.
- TensÃ¶rler: `X -> float32`, `y -> float32` (BCE uyumu). Gerekirse standardizasyon uygulayÄ±n.

### Not

- Kod parÃ§asÄ±nda `fromsklearn` yazÄ±mÄ± hatalÄ±dÄ±r; `from sklearn ...` olmalÄ±dÄ±r.

<a id="bc-dataset"></a>

## Breast Cancer: Dataset ve DataLoader

### Ã–zet

- `Dataset` sÄ±nÄ±fÄ± ile Ã¶rnek/etiket dÃ¶ndÃ¼rÃ¼n; `DataLoader` ile `batch_size=16`, eÄŸitimde `shuffle=True`.

### Ä°pucu

- `y` tensÃ¶rÃ¼nÃ¼n ÅŸekli Ã§oÄŸunlukla `[N]` veya `[N,1]` olur; BCE iÃ§in model Ã§Ä±ktÄ±sÄ±yla eÅŸleÅŸtiÄŸinden emin olun (gerekirse `labels.view(-1,1)`).

<a id="bc-model"></a>

## Breast Cancer: Model (Sigmoid vs Logit)

### Mimari

- Tam baÄŸlÄ± katmanlar: `input_size=30 â†’ 10 â†’ 10 â†’ 1`.
- Ã‡Ä±kÄ±ÅŸ: Ä°ki seÃ§enek
    - SeÃ§enek A (BCELoss): Ã‡Ä±kÄ±ÅŸta `sigmoid` uygula ve `nn.BCELoss()` kullan.
    - SeÃ§enek B (Ã–nerilir): Ã‡Ä±kÄ±ÅŸta aktivasyon yok (logit) ve `nn.BCEWithLogitsLoss()` kullan.

### Neden B Tercih Edilir?

- `BCEWithLogitsLoss`, sigmoid + BCEâ€™yi tek adÄ±mda sayÄ±sal olarak kararlÄ± ÅŸekilde uygular; taÅŸmalarÄ± ve hassasiyet kaybÄ±nÄ± azaltÄ±r.

<a id="bc-train"></a>

## Breast Cancer: EÄŸitim

### Kurulum

- Ã–ÄŸrenme oranÄ±: 0.01, epoch: 100, optimizer: Adam.
- KayÄ±p: `BCELoss` ise model Ã§Ä±kÄ±ÅŸÄ± `sigmoid(fc3(x))` ve etiket `float` olmalÄ±; `BCEWithLogitsLoss` ise model Ã§Ä±kÄ±ÅŸÄ±nda sigmoid olmasÄ±n.

### DÃ¶ngÃ¼

- Her batch: forward â†’ loss â†’ zero_grad â†’ backward â†’ step. Gerekirse `labels = labels.view(-1,1)` ile ÅŸekil eÅŸleÅŸtir.

### SÄ±nÄ±f DengesizliÄŸi

- `pos_weight` (BCEWithLogitsLoss argÃ¼manÄ±) veya `class_weight` ile dengesiz veri setlerinde pozitif sÄ±nÄ±fÄ± dengeleyin.

<a id="bc-eval"></a>

## Breast Cancer: DeÄŸerlendirme ve EÅŸikleme

### AdÄ±mlar

- `model.eval()`, `torch.no_grad()`.
- EÄŸer Ã§Ä±kÄ±ÅŸ logit ise: `probs = torch.sigmoid(outputs)`; sonra `pred = (probs > 0.5).float()`.
- EÄŸer Ã§Ä±kÄ±ÅŸ zaten olasÄ±lÄ±k ise: doÄŸrudan `pred = (outputs > 0.5).float()`.
- DoÄŸruluk: `correct/total`; ayrÄ±ca ROC-AUC, F1 gibi metrikler kullanÄ±n.

### Not

- Ã–rnekteki Ã§Ä±ktÄ± etiketi "EÄŸitim Veri Seti DoÄŸruluÄŸu" olarak yazÄ±lmÄ±ÅŸ; deÄŸerlendirme test setinde yapÄ±ldÄ±ÄŸÄ±ndan metin "Test Veri Seti DoÄŸruluÄŸu" olmalÄ±dÄ±r.

<a id="bc-predict"></a>

## Breast Cancer: Tahmin ve Girdi Åekli

### Not

- `torch.rand(30)` tek boyutlu tensÃ¶r modelin `forward` metodu `[N, 30]` beklediÄŸinde hata verebilir. Tek bir Ã¶rnek iÃ§in `random_inputs = torch.rand(1, 30)` ÅŸeklinde kullanÄ±n.

### HÄ±zlÄ± Sorular

1) Neden `BCEWithLogitsLoss` genellikle `BCELoss`â€™tan daha kararlÄ±dÄ±r?
2) EÅŸik (0.5) yerine ROC-AUC Ã¼zerinde karar eÅŸiÄŸi seÃ§menin avantajÄ± nedir?

<a id="mnist-overview"></a>

## MNIST: Veri KÃ¼mesi ve GÃ¶rselleÅŸtirme

### Ã–zet

- MNIST, 28Ã—28 piksel, tek kanallÄ± (gri) el yazÄ±sÄ± rakamlardan oluÅŸur: 60K eÄŸitim, 10K test gÃ¶rÃ¼ntÃ¼sÃ¼; etiketler 0â€“9.

### YÃ¼kleme ve Ä°lk GÃ¶rÃ¼ntÃ¼

- `torchvision.datasets.MNIST(root, train, download, transform)` ile indirilir.
- `DataLoader` ile `batch_size` seÃ§ilerek eÄŸitime hazÄ±r hale getirilir.
- GÃ¶rselleÅŸtirme iÃ§in ilk batchâ€™ten bir Ã¶rnek alÄ±p `plt.imshow(tensor.squeeze(), cmap='gray')` ile gÃ¶sterilebilir.

### Not

- DataLoaderâ€™da test iÃ§in `test_set` kullanÄ±n; `test_loader = DataLoader(test_set, ...)` (bazÄ± Ã¶rneklerde yanlÄ±ÅŸlÄ±kla `train_set` kullanabiliyor).

<a id="mnist-transforms"></a>

## MNIST: DÃ¶nÃ¼ÅŸÃ¼mler (ToTensor, Normalize)

### Ã–zet

- `transforms.ToTensor()` gÃ¶rÃ¼ntÃ¼yÃ¼ [0,1] aralÄ±ÄŸÄ±nda `[C,H,W]` tensÃ¶re Ã§evirir.
- Normalizasyon, Ã¶ÄŸrenmeyi hÄ±zlandÄ±rÄ±r ve kararlÄ± kÄ±lar; MNIST iÃ§in tipik: `Normalize(mean=[0.1307], std=[0.3081])`.

### Ã–rnek

- `transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.1307],[0.3081])])`.

<a id="mnist-mlp"></a>

## MNIST: MLP Baseline (Flatten + FC)

### Ã–zet

- EvriÅŸim kullanmadan basit bir MLP kurmak iÃ§in giriÅŸ 28Ã—28 â†’ 784â€™e dÃ¼zleÅŸtirilir, birkaÃ§ tam baÄŸlÄ± katman ve ReLU kullanÄ±lÄ±r, Ã§Ä±kÄ±ÅŸta 10 logit Ã¼retilir.

### Mimari

- `Flatten â†’ Linear(784,128) â†’ ReLU â†’ Linear(128,64) â†’ ReLU â†’ Linear(64,10)`; kayÄ±p: `CrossEntropyLoss` (logits bekler; Ã§Ä±kÄ±ÅŸta softmax yok).

### Not

- BazÄ± Ã¶rnek notlarda â€œ3 Ã§Ä±kÄ±ÅŸ nÃ¶ronuâ€ ifadesi geÃ§iyor; MNIST iÃ§in `num_classes=10` olmalÄ±dÄ±r.

<a id="mnist-train-eval"></a>

## MNIST: EÄŸitim ve DeÄŸerlendirme

### EÄŸitim

- `optimizer = Adam(model.parameters(), lr=0.01)`; epoch dÃ¶ngÃ¼sÃ¼nde `outputs = model(features)`, `loss = criterion(outputs, labels)`, `zero_grad â†’ backward â†’ step`.

### DeÄŸerlendirme

- `model.eval()` ve `torch.no_grad()` ile doÄŸruluk: `_, predicted = torch.max(outputs, 1)`; `correct/total`.

### HÄ±zlÄ± Sorular

1) Neden Ã§Ä±kÄ±ÅŸta softmax uygulamÄ±yoruz? (CELoss ile birlikte sayÄ±sal kararlÄ±lÄ±k)
2) Normalize etmeden eÄŸitirseniz ne gÃ¶zlemlersiniz?

<a id="gpu-usage"></a>

## GPU KullanÄ±mÄ± (CUDA vs CPU)

### AdÄ±mlar

1) Cihaz: `device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')`.
2) Model: `model.to(device)`.
3) EÄŸitim: dÃ¶ngÃ¼de `inputs, labels = inputs.to(device), labels.to(device)`.

### Not

- Model ve verinin aynÄ± cihazda olmasÄ± gerekir; aksi halde hata alÄ±nÄ±r.

<a id="why-mlp-bad-for-images"></a>

## Neden MLP GÃ¶rÃ¼ntÃ¼ler Ä°Ã§in Ä°deal DeÄŸil?

### Ã–zet

- Parametre patlamasÄ±: 200Ã—200Ã—3 giriÅŸ, 10 gizli nÃ¶ronlu bir katman iÃ§in â‰ˆ 1.2M parametre. Yerel yapÄ± ve uzaysal yakÄ±nlÄ±k bilgisi kaybolur.

### Not

- Pikseller arasÄ± komÅŸuluk bilgisi tam baÄŸlÄ± katmanlarda kullanÄ±lmaz; bu da veri/verim gereksinimini artÄ±rÄ±r.

<a id="local-regions"></a>

## Yerel BÃ¶lgeler ve Sezgi

### Ã–zet

- Ä°nsanlar nesneleri yerel ipuÃ§larÄ±ndan tanÄ±r; evriÅŸim yaklaÅŸÄ±mÄ± da yerel bÃ¶lgeler Ã¼zerinde Ã§alÄ±ÅŸarak bu sezgiyi takip eder.

<a id="cnn-conv"></a>

## CNN: EvriÅŸimli Katmanlar ve AÄŸÄ±rlÄ±k PaylaÅŸÄ±mÄ±

### Ã–zet

- KÃ¼Ã§Ã¼k filtreler (Ã¶rn. 3Ã—3, 5Ã—5) gÃ¶rÃ¼ntÃ¼ Ã¼zerinde kaydÄ±rÄ±lÄ±r; aynÄ± aÄŸÄ±rlÄ±klar her konumda kullanÄ±lÄ±r (aÄŸÄ±rlÄ±k paylaÅŸÄ±mÄ±). Bu, parametre verimliliÄŸi ve Ã¶telemeye karÅŸÄ± denkliÄŸi saÄŸlar.

### Notlar

- Ã–ÄŸrenilen filtreler kenar, kÃ¶ÅŸe, doku gibi Ã¶zellikleri yakalar; filtre sayÄ±sÄ± arttÄ±kÃ§a hesaplama maliyeti artar.

<a id="cnn-stride-padding"></a>

## CNN: Stride ve Padding

### Kavramlar

- Stride (adÄ±m): Filtrenin her hamlede kaÃ§ piksel kaydÄ±ÄŸÄ±; daha bÃ¼yÃ¼k stride â†’ daha kÃ¼Ã§Ã¼k Ã§Ä±ktÄ± boyutu.
- Padding (dolgu): Kenarlara sÄ±fÄ±r ekleyerek boyutu koruma ve kenar bilgisini koruma.

### Ã‡Ä±kÄ±ÅŸ Boyutu

$$W' = \left\lceil \frac{W - F + 2P}{S} \right\rceil + 1,\quad H' = \left\lceil \frac{H - F + 2P}{S} \right\rceil + 1$$

<a id="cnn-norm"></a>

## CNN: Normalizasyon KatmanlarÄ±

### Ã–zet

- Ã–zelliklerin normalize edilmesi optimizasyonu hÄ±zlandÄ±rÄ±r ve gradyanlarÄ± dengeler. YaygÄ±n katman: Batch Normalization.

### FormÃ¼l (BatchNorm, kanal baÅŸÄ±na)

$$\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}, \quad y = \gamma \, \hat{x} + \beta$$

<a id="cnn-pooling"></a>

## CNN: Havuzlama (Pooling)

### Ã–zet

- Kanal baÅŸÄ±na ayrÄ± uygulanÄ±r; uzaysal boyutu kÃ¼Ã§Ã¼ltÃ¼r, baskÄ±n Ã¶zellikleri Ã¶ne Ã§Ä±karÄ±r; parametre iÃ§ermez. Max/Avg tÃ¼rleri yaygÄ±ndÄ±r.

### Not

- KomÅŸu Ã¶zellikler benzer olabileceÄŸi iÃ§in bilgi kaybÄ± sÄ±nÄ±rlÄ±dÄ±r; aÅŸÄ±rÄ± havuzlama temsili zayÄ±flatabilir.

<a id="cnn-flat-dropout"></a>

## CNN: Flatten ve Dropout

### Ã–zet

- Flatten: KonvolÃ¼syonel Ã¶zellik haritalarÄ±nÄ± tam baÄŸlÄ± katmanlara baÄŸlamak iÃ§in tek boyutlu vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
- Dropout: EÄŸitim sÄ±rasÄ±nda rastgele nÃ¶ronlarÄ± devre dÄ±ÅŸÄ± bÄ±rakÄ±p aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi azaltÄ±r (Ã¶r. p=0.5).

<a id="cnn-simple-arch"></a>

## CNN: Basit Mimari AkÄ±ÅŸÄ± (MNIST)

### AkÄ±ÅŸ

- `Conv(1â†’16, k=5, p=2) â†’ ReLU â†’ MaxPool(2)
    â†’ Conv(16â†’32, k=5, p=2) â†’ ReLU â†’ MaxPool(2)
    â†’ Flatten (32Ã—7Ã—7=1568) â†’ Linear(1568,128) â†’ Dropout(0.5) â†’ Linear(128,10)`

### Notlar

- Girdi ÅŸekli `[B,1,28,28]`; padding sayesinde bazÄ± katmanlarda geniÅŸlik/yÃ¼kseklik korunur. Ã‡Ä±kÄ±ÅŸ katmanÄ± logits dÃ¶ndÃ¼rÃ¼r; kayÄ±p `CrossEntropyLoss`.

<a id="regression-problem"></a>

## Regresyon: Problem ve DÃ¶nÃ¼ÅŸÃ¼m

### Ã–zet

- Regresyon problemlerinde hedef deÄŸiÅŸken sÃ¼reklidir (Ã¶r. kan ÅŸekeri seviyesi). Ã‡ok sÄ±nÄ±flÄ±/ikili sÄ±nÄ±flandÄ±rmaya uygun bir aÄŸÄ±, regresyona uyarlamak iÃ§in Ã§Ä±ktÄ± katmanÄ±nÄ± lineer ve boyutunu 1 yapar, uygun bir regresyon kaybÄ± (MSE/MAE) seÃ§eriz.

### DÃ¶nÃ¼ÅŸÃ¼m Ä°lkeleri

- Ã‡Ä±ktÄ±: $\hat{y} = a$ (lineer; aktivasyon yok).
- KayÄ±p: MSE/MAE gibi regresyon kayÄ±plarÄ±; MSE yaygÄ±n ve tÃ¼revlenebilir.
- Metrikler: RMSE, MAE, $R^2$.
- Etiket tipi: `float32`.

### HÄ±zlÄ± Sorular

1) Neden regresyonda Ã§Ä±kÄ±ÅŸta aktivasyon kullanmÄ±yoruz?
2) MSE ve MAEâ€™nin hataya duyarlÄ±lÄ±ÄŸÄ± nasÄ±l farklÄ±dÄ±r?

<a id="diabetes-load-split"></a>

## Diabetes: Veriyi YÃ¼kleme ve BÃ¶lme

### AdÄ±mlar

- `load_diabetes()` ile veriyi yÃ¼kleyin; $X \in \mathbb{R}^{N\times 10}$, $y \in \mathbb{R}$.
- `train_test_split(X, y, test_size=0.2, random_state=42)`.
- TensÃ¶r tipleri: `X -> float32`, `y -> float32` (not: bazÄ± ders notlarÄ±nda "long" yazabilir; regresyonda `float` kullanÄ±lmalÄ±dÄ±r).

### Ä°pucu

- StandartlaÅŸtÄ±rma (Ã¶zellik ve hedef) eÄŸitimi kararlÄ± ve hÄ±zlÄ± yapar; hedef standardizasyonu raporlamada geri dÃ¶nÃ¼ÅŸtÃ¼rmeyi gerektirir.

<a id="diabetes-dataset"></a>

## Diabetes: Dataset ve DataLoader

### Ã–zet

- `DiabetDataset` ile Ã¶rnek/etiket dÃ¶ndÃ¼rÃ¼n; `DataLoader(batch_size=16, shuffle=True)`.

### Not

- Etiketin ÅŸekli `[N]` veya `[N,1]` olabilir; MSELoss ile ÅŸekil uyuÅŸmazlÄ±ÄŸÄ±nda `labels.view(-1,1)` kullanÄ±n veya modelinizi `[N]` dÃ¶ndÃ¼recek ÅŸekilde ayarlayÄ±n.

<a id="diabetes-model"></a>

## Diabetes: Model (Lineer Ã‡Ä±kÄ±ÅŸ)

### Mimari

- Tam baÄŸlÄ±: `input_size=10 â†’ 10 â†’ 10 â†’ 1`; ara katmanlarda ReLU; Ã§Ä±kÄ±ÅŸ katmanÄ±nda aktivasyon YOK (lineer).

### Not

- SÄ±nÄ±flandÄ±rma Ã¶rneÄŸinden kalan isim `SimpleClassifier` olsa da, fonksiyonel olarak bu bir regresÃ¶rdÃ¼r; isimlendirme semantiktir.

<a id="diabetes-train"></a>

## Diabetes: EÄŸitim

### Kurulum

- KayÄ±p: `nn.MSELoss()`; optimizer: Adam; lr=0.01; epoch=100 (Ã¶rnek).

### DÃ¶ngÃ¼

- Her batch: forward â†’ `loss = MSE(outputs, labels.view(-1,1))` â†’ zero_grad â†’ backward â†’ step.

### HÄ±zlÄ± Sorular

1) Hedef standardizasyonu (y scaling) RMSE yorumunu nasÄ±l etkiler?
2) Hangi durumda Huber loss (Smooth L1) MSEâ€™ye tercih edilebilir?

<a id="diabetes-eval"></a>

## Diabetes: DeÄŸerlendirme (MSE/RMSE)

### FormÃ¼ller

- MSE: $$\mathrm{MSE} = \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i)^2$$
- RMSE: $$\mathrm{RMSE} = \sqrt{\mathrm{MSE}}$$

### Uygulama Notu

- Toplam hata `reduction='sum'` ile toplanÄ±p Ã¶rnek sayÄ±sÄ±na bÃ¶lÃ¼nerek MSE elde edilir; RMSE iÃ§in karekÃ¶k alÄ±nÄ±r. Ek metrik: MAE, $R^2$.

<a id="digital-image-types"></a>

## Dijital GÃ¶rÃ¼ntÃ¼: Temel TÃ¼rler

### Ã–zet

- Dijital gÃ¶rÃ¼ntÃ¼ler, piksellerden oluÅŸur ve her piksel bir veya daha Ã§ok kanal deÄŸerine sahiptir. YaygÄ±n tÃ¼rler: Ä°kili (Binary), Gri Seviye, Renkli (RGB).

### KarÅŸÄ±laÅŸtÄ±rma

- Ä°kili: Her piksel 0/1 (veya 0/255) â€” maskeleme/bÃ¶lÃ¼tleme iÃ§in kullanÄ±ÅŸlÄ±.
- Gri Seviye: Tek kanal, tipik olarak 8-bit (0â€“255) parlaklÄ±k deÄŸeri.
- Renkli (RGB): ÃœÃ§ kanal (R,G,B); her kanal bir gri seviye gÃ¶rÃ¼ntÃ¼dÃ¼r; birleÅŸimi renkli gÃ¶rÃ¼ntÃ¼yÃ¼ verir.

### HÄ±zlÄ± Sorular

1) Hangi gÃ¶rÃ¼ntÃ¼ tÃ¼rÃ¼ maskeleme iÃ§in en uygundur ve neden?
2) 8-bit ile 16-bit gri seviye arasÄ±ndaki temel fark nedir?

<a id="binary-image"></a>

## Ä°kili (Binary) GÃ¶rÃ¼ntÃ¼

### Ã–zet

- Her piksel yalnÄ±zca iki deÄŸerden birini alÄ±r: arka plan (0/siyah) veya nesne (1/beyaz). EÅŸikleme (thresholding), doku analizi ya da bÃ¶lÃ¼tleme Ã§Ä±ktÄ±larÄ±nÄ±n temsiliyle elde edilebilir.

### KullanÄ±mlar

- Maskeleme: Ä°lgili bÃ¶lgeyi 1 ile, diÄŸerlerini 0 ile iÅŸaretleyerek diÄŸer iÅŸlemlerden izole etmek.
- Basit ÅŸekil analizi: Alan, Ã§evre, baÄŸÄ±l konum Ã¶lÃ§Ã¼mleri.

### Notlar

- â€œÄ°kilileÅŸtirme (binarization)â€ gri seviye veya renkli kanallardan eÅŸikleme ile yapÄ±lÄ±r. Otsu vb. otomatik eÅŸikleme yÃ¶ntemleri de vardÄ±r.

### HÄ±zlÄ± Sorular

1) Global ve adaptif eÅŸikleme arasÄ±ndaki fark nedir?

<a id="grayscale-image"></a>

## Gri Seviyeli GÃ¶rÃ¼ntÃ¼

### Ã–zet

- Tek kanallÄ± parlaklÄ±k (intensity) gÃ¶rÃ¼ntÃ¼sÃ¼dÃ¼r. 8-bit gri seviye iÃ§in her piksel 0â€“255 aralÄ±ÄŸÄ±ndadÄ±r; 0 siyah, 255 beyaz, arasÄ± gri tonlar.

### Bit DerinliÄŸi

- Bit sayÄ±sÄ± arttÄ±kÃ§a ayÄ±rt edilebilir seviye sayÄ±sÄ± artar: 8-bit â†’ 256 seviye, 16-bit â†’ 65,536 seviye.

### Notlar

- GÃ¶rÃ¼ntÃ¼ boyutu (NÃ—M), gri seviye aralÄ±ÄŸÄ± G={0,...,255} (8-bit). SayÄ±sallaÅŸtÄ±rma esnasÄ±nda Ã¶rnekleme (uzaysal Ã§Ã¶zÃ¼nÃ¼rlÃ¼k) ve nicemleme (parlaklÄ±k Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼) belirlenir.

### HÄ±zlÄ± Sorular

1) Nicemleme seviyesini artÄ±rmak hangi durumlarda gÃ¶zle gÃ¶rÃ¼lÃ¼r fayda saÄŸlar?

<a id="color-image-rgb"></a>

## Renkli GÃ¶rÃ¼ntÃ¼ (RGB)

### Ã–zet

- Renkli gÃ¶rÃ¼ntÃ¼, Ã¼Ã§ gri seviye kanaldan oluÅŸur: R (kÄ±rmÄ±zÄ±), G (yeÅŸil), B (mavi). Her kanal 0â€“255 arasÄ±nda deÄŸer alÄ±r (8-bit). Piksel rengi (R,G,B) Ã¼Ã§lÃ¼sÃ¼yle ifade edilir; beyaz (255,255,255), siyah (0,0,0).

### Temsil ve Boyutlar

- Veri yapÄ±sÄ± genellikle (YÃ¼kseklik, GeniÅŸlik, Kanal) veya (Kanal, YÃ¼kseklik, GeniÅŸlik) dÃ¼zendedir.
- 8-bit RGB teorik kombinasyon sayÄ±sÄ± 256Ã—256Ã—256 = 16,777,216 renk (yaklaÅŸÄ±k 16.7M) Ã¼retir.

### Notlar

- FarklÄ± renk uzaylarÄ± (HSV, Lab) belirli gÃ¶revlerde avantaj saÄŸlar (Ã¶r. parlaklÄ±k/renk bileÅŸenlerini ayrÄ±ÅŸtÄ±rma). Derin Ã¶ÄŸrenmede ham RGB sÄ±k kullanÄ±lÄ±r; Ã¶n-iÅŸleme olarak normalizasyon yapÄ±lÄ±r.

### HÄ±zlÄ± Sorular

1) Neden bazÄ± modeller (C,H,W) kanal-Ã¶ncelikli dÃ¼zeni tercih eder?
2) RGB yerine HSV kullanmanÄ±n faydasÄ± hangi gÃ¶revlerde ortaya Ã§Ä±kar?
